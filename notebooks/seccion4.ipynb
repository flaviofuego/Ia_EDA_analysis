{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "```\n",
    "================================================================================\n",
    "PROYECTO FINAL - INTELIGENCIA ARTIFICIAL\n",
    "SECCI\u00d3N 4: APRENDIZAJE SUPERVISADO (TAREAS 13, 14, 15, 16, 17)\n",
    "================================================================================\n",
    "Universidad del Norte - Ingenier\u00eda de Sistemas\n",
    "Profesor: Eduardo Zurek, Ph.D.\n",
    "\n",
    "OBJETIVO: Entrenar y evaluar modelos de clasificaci\u00f3n supervisada para predecir\n",
    "el nivel de desempe\u00f1o en ingl\u00e9s (DESEMP_INGLES) a partir de las variables\n",
    "preprocesadas.\n",
    "================================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "init",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFIGURACI\u00d3N INICIAL E IMPORTACIONES\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pickle\n",
    "import json\n",
    "from time import time\n",
    "\n",
    "# Scikit-learn imports - Modelos\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# M\u00e9tricas y validaci\u00f3n\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score,\n",
    "    roc_curve, precision_recall_curve, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score, cross_validate, StratifiedKFold,\n",
    "    GridSearchCV, RandomizedSearchCV\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TARGET_COLUMN = 'DESEMP_INGLES'\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SECCI\u00d3N 4: APRENDIZAJE SUPERVISADO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\ud83d\udccc Random State: {RANDOM_STATE}\")\n",
    "print(f\"\ud83c\udfaf Variable Objetivo: {TARGET_COLUMN}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CARGAR DATOS PREPROCESADOS\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CARGANDO DATOS PREPROCESADOS DE SECCI\u00d3N 2\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "try:\n",
    "    # Cargar train/test split\n",
    "    with open('train_test_split.pkl', 'rb') as f:\n",
    "        train_test_data = pickle.load(f)\n",
    "    \n",
    "    X_train = train_test_data['X_train']\n",
    "    X_test = train_test_data['X_test']\n",
    "    y_train = train_test_data['y_train']\n",
    "    y_test = train_test_data['y_test']\n",
    "    y_train_original = train_test_data['y_train_original']\n",
    "    y_test_original = train_test_data['y_test_original']\n",
    "    \n",
    "    print(f\"\u2705 X_train: {X_train.shape}\")\n",
    "    print(f\"\u2705 X_test: {X_test.shape}\")\n",
    "    print(f\"\u2705 y_train: {y_train.shape}\")\n",
    "    print(f\"\u2705 y_test: {y_test.shape}\")\n",
    "    \n",
    "    # Cargar objetos de preprocesamiento\n",
    "    with open('preprocessing_objects.pkl', 'rb') as f:\n",
    "        preprocessing_objects = pickle.load(f)\n",
    "    \n",
    "    le_target = preprocessing_objects['label_encoder_target']\n",
    "    target_mapping = preprocessing_objects['target_mapping']\n",
    "    final_features = preprocessing_objects['final_features']\n",
    "    \n",
    "    print(f\"\\n\u2705 Mapeo de clases: {target_mapping}\")\n",
    "    print(f\"\u2705 Features: {len(final_features)}\")\n",
    "    \n",
    "    # Cargar PCA (opcional)\n",
    "    try:\n",
    "        with open('pca_models.pkl', 'rb') as f:\n",
    "            pca_objects = pickle.load(f)\n",
    "        X_train_pca = pca_objects['X_train_pca']\n",
    "        X_test_pca = pca_objects['X_test_pca']\n",
    "        optimal_n_components = pca_objects['optimal_n_components']\n",
    "        print(f\"\u2705 PCA disponible: {optimal_n_components} componentes\")\n",
    "    except:\n",
    "        X_train_pca = None\n",
    "        X_test_pca = None\n",
    "        print(\"\u26a0\ufe0f  PCA no disponible\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\u274c Error cargando datos: {e}\")\n",
    "    print(\"\u26a0\ufe0f  Ejecuta primero la Secci\u00f3n 2 (Preprocesamiento)\")\n",
    "    raise\n",
    "\n",
    "# Verificar distribuci\u00f3n de clases\n",
    "print(\"\\n\ud83d\udcca DISTRIBUCI\u00d3N DE CLASES:\")\n",
    "for i, label in enumerate(le_target.classes_):\n",
    "    n_train = np.sum(y_train == i)\n",
    "    n_test = np.sum(y_test == i)\n",
    "    pct_train = n_train / len(y_train) * 100\n",
    "    pct_test = n_test / len(y_test) * 100\n",
    "    print(f\"   {label}: Train={n_train:,} ({pct_train:.1f}%), Test={n_test:,} ({pct_test:.1f}%)\")\n",
    "\n",
    "print(\"\\n\u2705 Datos cargados correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TAREA 13: ENTRENAMIENTO DE MODELOS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"TAREA 13: ENTRENAMIENTO DE MODELOS DE CLASIFICACI\u00d3N\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "\"\"\"\n",
    "Entrenaremos m\u00faltiples modelos de clasificaci\u00f3n:\n",
    "1. Decision Tree - Modelo interpretable basado en reglas\n",
    "2. Random Forest - Ensemble de \u00e1rboles de decisi\u00f3n\n",
    "3. Logistic Regression - Modelo lineal probabil\u00edstico\n",
    "4. Support Vector Machine (SVM) - Modelo de margen m\u00e1ximo\n",
    "5. K-Nearest Neighbors (KNN) - Modelo basado en instancias\n",
    "\"\"\"\n",
    "\n",
    "# Diccionario para almacenar modelos y resultados\n",
    "models = {}\n",
    "predictions = {}\n",
    "training_times = {}\n",
    "\n",
    "# ==================\n",
    "# MODELO 1: DECISION TREE\n",
    "# ==================\n",
    "\n",
    "print(\"13.1 DECISION TREE CLASSIFIER\")\n",
    "print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "print(\"Configuraci\u00f3n:\")\n",
    "print(\"   \u2022 max_depth = 15\")\n",
    "print(\"   \u2022 min_samples_split = 100\")\n",
    "print(\"   \u2022 min_samples_leaf = 50\")\n",
    "print(\"   \u2022 criterion = 'gini'\")\n",
    "\n",
    "start_time = time()\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=15,\n",
    "    min_samples_split=100,\n",
    "    min_samples_leaf=50,\n",
    "    criterion='gini',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_time = time() - start_time\n",
    "\n",
    "models['Decision Tree'] = dt_model\n",
    "predictions['Decision Tree'] = dt_model.predict(X_test)\n",
    "training_times['Decision Tree'] = dt_time\n",
    "\n",
    "print(f\"\\n\u2705 Decision Tree entrenado en {dt_time:.2f}s\")\n",
    "print(f\"   \u2022 N\u00famero de nodos: {dt_model.tree_.node_count}\")\n",
    "print(f\"   \u2022 Profundidad del \u00e1rbol: {dt_model.tree_.max_depth}\")\n",
    "\n",
    "# ==================\n",
    "# MODELO 2: RANDOM FOREST\n",
    "# ==================\n",
    "\n",
    "print(\"\\n\\n13.2 RANDOM FOREST CLASSIFIER\")\n",
    "print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "print(\"Configuraci\u00f3n:\")\n",
    "print(\"   \u2022 n_estimators = 100\")\n",
    "print(\"   \u2022 max_depth = 15\")\n",
    "print(\"   \u2022 min_samples_split = 50\")\n",
    "print(\"   \u2022 min_samples_leaf = 25\")\n",
    "\n",
    "start_time = time()\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=50,\n",
    "    min_samples_leaf=25,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_time = time() - start_time\n",
    "\n",
    "models['Random Forest'] = rf_model\n",
    "predictions['Random Forest'] = rf_model.predict(X_test)\n",
    "training_times['Random Forest'] = rf_time\n",
    "\n",
    "print(f\"\\n\u2705 Random Forest entrenado en {rf_time:.2f}s\")\n",
    "print(f\"   \u2022 N\u00famero de \u00e1rboles: {rf_model.n_estimators}\")\n",
    "\n",
    "# ==================\n",
    "# MODELO 3: LOGISTIC REGRESSION\n",
    "# ==================\n",
    "\n",
    "print(\"\\n\\n13.3 LOGISTIC REGRESSION\")\n",
    "print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "print(\"Configuraci\u00f3n:\")\n",
    "print(\"   \u2022 solver = 'lbfgs'\")\n",
    "print(\"   \u2022 max_iter = 1000\")\n",
    "print(\"   \u2022 multi_class = 'multinomial'\")\n",
    "\n",
    "start_time = time()\n",
    "lr_model = LogisticRegression(\n",
    "    solver='lbfgs',\n",
    "    max_iter=1000,\n",
    "    multi_class='multinomial',\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_time = time() - start_time\n",
    "\n",
    "models['Logistic Regression'] = lr_model\n",
    "predictions['Logistic Regression'] = lr_model.predict(X_test)\n",
    "training_times['Logistic Regression'] = lr_time\n",
    "\n",
    "print(f\"\\n\u2705 Logistic Regression entrenado en {lr_time:.2f}s\")\n",
    "\n",
    "# ==================\n",
    "# MODELO 4: SUPPORT VECTOR MACHINE\n",
    "# ==================\n",
    "\n",
    "print(\"\\n\\n13.4 SUPPORT VECTOR MACHINE (SVM)\")\n",
    "print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "print(\"Configuraci\u00f3n:\")\n",
    "print(\"   \u2022 kernel = 'rbf'\")\n",
    "print(\"   \u2022 C = 1.0\")\n",
    "print(\"   \u2022 gamma = 'scale'\")\n",
    "print(\"\u26a0\ufe0f  Usando muestra de 20,000 observaciones por eficiencia...\\n\")\n",
    "\n",
    "# SVM es costoso, usar muestra\n",
    "sample_indices = np.random.choice(len(X_train), min(20000, len(X_train)), replace=False)\n",
    "X_train_svm = X_train.iloc[sample_indices]\n",
    "y_train_svm = y_train.iloc[sample_indices]\n",
    "\n",
    "start_time = time()\n",
    "svm_model = SVC(\n",
    "    kernel='rbf',\n",
    "    C=1.0,\n",
    "    gamma='scale',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "svm_model.fit(X_train_svm, y_train_svm)\n",
    "svm_time = time() - start_time\n",
    "\n",
    "models['SVM'] = svm_model\n",
    "predictions['SVM'] = svm_model.predict(X_test)\n",
    "training_times['SVM'] = svm_time\n",
    "\n",
    "print(f\"\u2705 SVM entrenado en {svm_time:.2f}s\")\n",
    "print(f\"   \u2022 Support vectors: {svm_model.n_support_.sum()}\")\n",
    "\n",
    "# ==================\n",
    "# MODELO 5: K-NEAREST NEIGHBORS\n",
    "# ==================\n",
    "\n",
    "print(\"\\n\\n13.5 K-NEAREST NEIGHBORS (KNN)\")\n",
    "print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "print(\"Configuraci\u00f3n:\")\n",
    "print(\"   \u2022 n_neighbors = 7\")\n",
    "print(\"   \u2022 weights = 'distance'\")\n",
    "print(\"   \u2022 metric = 'euclidean'\")\n",
    "\n",
    "start_time = time()\n",
    "knn_model = KNeighborsClassifier(\n",
    "    n_neighbors=7,\n",
    "    weights='distance',\n",
    "    metric='euclidean',\n",
    "    n_jobs=-1\n",
    ")\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_time = time() - start_time\n",
    "\n",
    "models['KNN'] = knn_model\n",
    "predictions['KNN'] = knn_model.predict(X_test)\n",
    "training_times['KNN'] = knn_time\n",
    "\n",
    "print(f\"\\n\u2705 KNN entrenado en {knn_time:.2f}s\")\n",
    "\n",
    "# Resumen\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN DE ENTRENAMIENTO\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for model_name, t in training_times.items():\n",
    "    print(f\"   {model_name:20s}: {t:7.2f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\u2705 TAREA 13 COMPLETADA\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TAREA 14: COMPARACI\u00d3N DE MODELOS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"TAREA 14: COMPARACI\u00d3N DE MODELOS CON M\u00c9TRICAS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Calcular m\u00e9tricas para cada modelo\n",
    "metrics_results = {}\n",
    "\n",
    "for model_name in models.keys():\n",
    "    y_pred = predictions[model_name]\n",
    "    \n",
    "    # Calcular m\u00e9tricas\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    # Para multi-clase, usar 'weighted' average\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    metrics_results[model_name] = {\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'Training Time': training_times[model_name]\n",
    "    }\n",
    "\n",
    "# Crear DataFrame de comparaci\u00f3n\n",
    "metrics_df = pd.DataFrame(metrics_results).T\n",
    "metrics_df = metrics_df.sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"\ud83d\udcca TABLA COMPARATIVA DE M\u00c9TRICAS:\\n\")\n",
    "print(metrics_df.to_string())\n",
    "\n",
    "# Visualizaci\u00f3n de comparaci\u00f3n\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Accuracy comparison\n",
    "metrics_df['Accuracy'].plot(kind='barh', ax=axes[0, 0], color='skyblue')\n",
    "axes[0, 0].set_xlabel('Accuracy', fontweight='bold')\n",
    "axes[0, 0].set_title('Comparaci\u00f3n de Accuracy', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].grid(axis='x', alpha=0.3)\n",
    "for i, v in enumerate(metrics_df['Accuracy']):\n",
    "    axes[0, 0].text(v + 0.005, i, f'{v:.4f}', va='center')\n",
    "\n",
    "# 2. F1-Score comparison\n",
    "metrics_df['F1-Score'].plot(kind='barh', ax=axes[0, 1], color='lightcoral')\n",
    "axes[0, 1].set_xlabel('F1-Score', fontweight='bold')\n",
    "axes[0, 1].set_title('Comparaci\u00f3n de F1-Score', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].grid(axis='x', alpha=0.3)\n",
    "for i, v in enumerate(metrics_df['F1-Score']):\n",
    "    axes[0, 1].text(v + 0.005, i, f'{v:.4f}', va='center')\n",
    "\n",
    "# 3. Precision vs Recall\n",
    "axes[1, 0].scatter(metrics_df['Precision'], metrics_df['Recall'], s=200, alpha=0.6)\n",
    "for idx, model in enumerate(metrics_df.index):\n",
    "    axes[1, 0].annotate(model, \n",
    "                       (metrics_df['Precision'].iloc[idx], metrics_df['Recall'].iloc[idx]),\n",
    "                       fontsize=9, ha='center')\n",
    "axes[1, 0].set_xlabel('Precision', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Recall', fontweight='bold')\n",
    "axes[1, 0].set_title('Precision vs Recall', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# 4. Training Time\n",
    "metrics_df['Training Time'].plot(kind='barh', ax=axes[1, 1], color='lightgreen')\n",
    "axes[1, 1].set_xlabel('Tiempo (segundos)', fontweight='bold')\n",
    "axes[1, 1].set_title('Tiempo de Entrenamiento', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].grid(axis='x', alpha=0.3)\n",
    "for i, v in enumerate(metrics_df['Training Time']):\n",
    "    axes[1, 1].text(v + 0.5, i, f'{v:.2f}s', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Matrices de confusi\u00f3n\n",
    "print(\"\\n\\n14.2 MATRICES DE CONFUSI\u00d3N\\n\")\n",
    "print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "n_models = len(models)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (model_name, y_pred) in enumerate(predictions.items()):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Normalizar por fila (porcentajes)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues', \n",
    "                xticklabels=le_target.classes_,\n",
    "                yticklabels=le_target.classes_,\n",
    "                ax=axes[idx], cbar=True)\n",
    "    \n",
    "    axes[idx].set_title(f'{model_name}\\n(Acc: {metrics_results[model_name][\"Accuracy\"]:.4f})', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Real', fontweight='bold')\n",
    "    axes[idx].set_xlabel('Predicho', fontweight='bold')\n",
    "\n",
    "# Hide last subplot if odd number of models\n",
    "if n_models < 6:\n",
    "    axes[5].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Classification reports\n",
    "print(\"\\n14.3 REPORTES DE CLASIFICACI\u00d3N DETALLADOS\\n\")\n",
    "print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "for model_name, y_pred in predictions.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"MODELO: {model_name}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    print(classification_report(y_test, y_pred, \n",
    "                                target_names=le_target.classes_,\n",
    "                                digits=4))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\u2705 TAREA 14 COMPLETADA\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TAREA 15: VALIDACI\u00d3N CRUZADA\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"TAREA 15: VALIDACI\u00d3N CRUZADA Y AN\u00c1LISIS DE ESTABILIDAD\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"15.1 CONFIGURACI\u00d3N DE K-FOLD CROSS-VALIDATION\")\n",
    "print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "# Configurar k-fold estratificado\n",
    "N_FOLDS = 5\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "print(f\"Configuraci\u00f3n: {N_FOLDS}-Fold Stratified Cross-Validation\")\n",
    "print(f\"   \u2022 N\u00famero de folds: {N_FOLDS}\")\n",
    "print(f\"   \u2022 Estratificaci\u00f3n: S\u00ed\")\n",
    "print(f\"   \u2022 Shuffle: S\u00ed\\n\")\n",
    "\n",
    "# M\u00e9tricas a evaluar\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision_weighted': 'precision_weighted',\n",
    "    'recall_weighted': 'recall_weighted',\n",
    "    'f1_weighted': 'f1_weighted'\n",
    "}\n",
    "\n",
    "# Realizar cross-validation para cada modelo\n",
    "cv_results = {}\n",
    "\n",
    "print(\"15.2 EJECUTANDO VALIDACI\u00d3N CRUZADA\\n\")\n",
    "print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluando {model_name}...\")\n",
    "    \n",
    "    # Para SVM, usar muestra por eficiencia\n",
    "    if model_name == 'SVM':\n",
    "        X_cv = X_train_svm\n",
    "        y_cv = y_train_svm\n",
    "    else:\n",
    "        X_cv = X_train\n",
    "        y_cv = y_train\n",
    "    \n",
    "    start_time = time()\n",
    "    cv_scores = cross_validate(\n",
    "        model, X_cv, y_cv, \n",
    "        cv=skf, \n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    cv_time = time() - start_time\n",
    "    \n",
    "    # Almacenar resultados\n",
    "    cv_results[model_name] = {\n",
    "        'accuracy_train': cv_scores['train_accuracy'],\n",
    "        'accuracy_test': cv_scores['test_accuracy'],\n",
    "        'precision_test': cv_scores['test_precision_weighted'],\n",
    "        'recall_test': cv_scores['test_recall_weighted'],\n",
    "        'f1_test': cv_scores['test_f1_weighted'],\n",
    "        'time': cv_time\n",
    "    }\n",
    "    \n",
    "    print(f\"   \u2705 Completado en {cv_time:.2f}s\\n\")\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "print(\"\\n15.3 RESULTADOS DE VALIDACI\u00d3N CRUZADA\\n\")\n",
    "print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "cv_summary = []\n",
    "for model_name, scores in cv_results.items():\n",
    "    cv_summary.append({\n",
    "        'Modelo': model_name,\n",
    "        'Accuracy (mean)': scores['accuracy_test'].mean(),\n",
    "        'Accuracy (std)': scores['accuracy_test'].std(),\n",
    "        'F1-Score (mean)': scores['f1_test'].mean(),\n",
    "        'F1-Score (std)': scores['f1_test'].std(),\n",
    "        'Train-Test Gap': scores['accuracy_train'].mean() - scores['accuracy_test'].mean()\n",
    "    })\n",
    "\n",
    "cv_summary_df = pd.DataFrame(cv_summary).sort_values('F1-Score (mean)', ascending=False)\n",
    "print(cv_summary_df.to_string(index=False))\n",
    "\n",
    "# Visualizaci\u00f3n de estabilidad\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Box plot de accuracy por fold\n",
    "data_accuracy = [cv_results[name]['accuracy_test'] for name in models.keys()]\n",
    "bp1 = axes[0, 0].boxplot(data_accuracy, labels=models.keys(), patch_artist=True)\n",
    "for patch in bp1['boxes']:\n",
    "    patch.set_facecolor('lightblue')\n",
    "axes[0, 0].set_ylabel('Accuracy', fontweight='bold')\n",
    "axes[0, 0].set_title(f'Distribuci\u00f3n de Accuracy ({N_FOLDS}-Fold CV)', \n",
    "                     fontsize=13, fontweight='bold')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Box plot de F1-Score por fold\n",
    "data_f1 = [cv_results[name]['f1_test'] for name in models.keys()]\n",
    "bp2 = axes[0, 1].boxplot(data_f1, labels=models.keys(), patch_artist=True)\n",
    "for patch in bp2['boxes']:\n",
    "    patch.set_facecolor('lightcoral')\n",
    "axes[0, 1].set_ylabel('F1-Score', fontweight='bold')\n",
    "axes[0, 1].set_title(f'Distribuci\u00f3n de F1-Score ({N_FOLDS}-Fold CV)', \n",
    "                     fontsize=13, fontweight='bold')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Train-Test Gap (overfitting indicator)\n",
    "gap_data = {name: scores['accuracy_train'].mean() - scores['accuracy_test'].mean() \n",
    "            for name, scores in cv_results.items()}\n",
    "axes[1, 0].barh(list(gap_data.keys()), list(gap_data.values()), color='orange', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Train-Test Accuracy Gap', fontweight='bold')\n",
    "axes[1, 0].set_title('Indicador de Overfitting\\n(Menor es mejor)', \n",
    "                     fontsize=13, fontweight='bold')\n",
    "axes[1, 0].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 0].grid(axis='x', alpha=0.3)\n",
    "for i, (k, v) in enumerate(gap_data.items()):\n",
    "    axes[1, 0].text(v + 0.002, i, f'{v:.4f}', va='center')\n",
    "\n",
    "# 4. Std deviation (stability indicator)\n",
    "std_data = {name: scores['accuracy_test'].std() for name, scores in cv_results.items()}\n",
    "axes[1, 1].barh(list(std_data.keys()), list(std_data.values()), color='lightgreen', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Desviaci\u00f3n Est\u00e1ndar (Accuracy)', fontweight='bold')\n",
    "axes[1, 1].set_title('Estabilidad del Modelo\\n(Menor es m\u00e1s estable)', \n",
    "                     fontsize=13, fontweight='bold')\n",
    "axes[1, 1].grid(axis='x', alpha=0.3)\n",
    "for i, (k, v) in enumerate(std_data.items()):\n",
    "    axes[1, 1].text(v + 0.0002, i, f'{v:.5f}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cross_validation_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\u2705 TAREA 15 COMPLETADA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n\ud83d\udca1 INTERPRETACI\u00d3N:\")\n",
    "print(\"   \u2022 Menor desviaci\u00f3n est\u00e1ndar = Mayor estabilidad\")\n",
    "print(\"   \u2022 Menor Train-Test Gap = Menos overfitting\")\n",
    "print(\"   \u2022 Mejor modelo: Alto F1, baja desviaci\u00f3n, bajo gap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================",
    "# TAREA 16: AJUSTE DE HIPERPAR\u00c1METROS",
    "# ============================================",
    "",
    "print(\"\\n\\n\" + \"=\"*80)",
    "print(\"TAREA 16: AJUSTE DE HIPERPAR\u00c1METROS\")",
    "print(\"=\"*80 + \"\\n\")",
    "",
    "\"\"\"",
    "Realizaremos Grid Search para los 2 mejores modelos de la Task 15.",
    "Para otros modelos, usaremos Random Search para mayor eficiencia.",
    "\"\"\"",
    "",
    "# Seleccionar los 2 mejores modelos seg\u00fan CV",
    "best_models = cv_summary_df.head(2)['Modelo'].tolist()",
    "print(f\"Modelos seleccionados para tuning: {best_models}\\n\")",
    "",
    "tuned_models = {}",
    "best_params_dict = {}",
    "",
    "# ==================",
    "# RANDOM FOREST - GRID SEARCH",
    "# ==================",
    "",
    "if 'Random Forest' in best_models:",
    "    print(\"16.1 RANDOM FOREST - GRID SEARCH\")",
    "    print(\"-\" * 80 + \"\\n\")",
    "    ",
    "    param_grid_rf = {",
    "        'n_estimators': [50, 100, 150],",
    "        'max_depth': [10, 15, 20],",
    "        'min_samples_split': [50, 100, 150],",
    "        'min_samples_leaf': [25, 50, 75]",
    "    }",
    "    ",
    "    print(\"Grid de par\u00e1metros:\")",
    "    for param, values in param_grid_rf.items():",
    "        print(f\"   \u2022 {param}: {values}\")",
    "    ",
    "    print(f\"\\nTotal de combinaciones: {np.prod([len(v) for v in param_grid_rf.values()])}\")",
    "    print(\"Ejecutando Grid Search...\\n\")",
    "    ",
    "    start_time = time()",
    "    grid_rf = GridSearchCV(",
    "        RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1),",
    "        param_grid_rf,",
    "        cv=3,  # 3-fold para eficiencia",
    "        scoring='f1_weighted',",
    "        n_jobs=-1,",
    "        verbose=1",
    "    )",
    "    grid_rf.fit(X_train, y_train)",
    "    rf_tuning_time = time() - start_time",
    "    ",
    "    tuned_models['Random Forest (Tuned)'] = grid_rf.best_estimator_",
    "    best_params_dict['Random Forest'] = grid_rf.best_params_",
    "    ",
    "    print(f\"\\n\u2705 Grid Search completado en {rf_tuning_time:.2f}s\")",
    "    print(f\"\\nMejores par\u00e1metros:\")",
    "    for param, value in grid_rf.best_params_.items():",
    "        print(f\"   \u2022 {param}: {value}\")",
    "    print(f\"\\nMejor F1-Score (CV): {grid_rf.best_score_:.4f}\")",
    "",
    "# ==================",
    "# LOGISTIC REGRESSION - GRID SEARCH  ",
    "# ==================",
    "",
    "if 'Logistic Regression' in best_models:",
    "    print(\"\\n\\n16.2 LOGISTIC REGRESSION - GRID SEARCH\")",
    "    print(\"-\" * 80 + \"\\n\")",
    "    ",
    "    param_grid_lr = {",
    "        'C': [0.001, 0.01, 0.1, 1.0, 10.0],",
    "        'solver': ['lbfgs', 'saga'],",
    "        'max_iter': [1000, 2000]",
    "    }",
    "    ",
    "    print(\"Grid de par\u00e1metros:\")",
    "    for param, values in param_grid_lr.items():",
    "        print(f\"   \u2022 {param}: {values}\")",
    "    ",
    "    print(f\"\\nTotal de combinaciones: {np.prod([len(v) for v in param_grid_lr.values()])}\")",
    "    print(\"Ejecutando Grid Search...\\n\")",
    "    ",
    "    start_time = time()",
    "    grid_lr = GridSearchCV(",
    "        LogisticRegression(random_state=RANDOM_STATE, multi_class='multinomial', n_jobs=-1),",
    "        param_grid_lr,",
    "        cv=3,",
    "        scoring='f1_weighted',",
    "        n_jobs=-1,",
    "        verbose=1",
    "    )",
    "    grid_lr.fit(X_train, y_train)",
    "    lr_tuning_time = time() - start_time",
    "    ",
    "    tuned_models['Logistic Regression (Tuned)'] = grid_lr.best_estimator_",
    "    best_params_dict['Logistic Regression'] = grid_lr.best_params_",
    "    ",
    "    print(f\"\\n\u2705 Grid Search completado en {lr_tuning_time:.2f}s\")",
    "    print(f\"\\nMejores par\u00e1metros:\")",
    "    for param, value in grid_lr.best_params_.items():",
    "        print(f\"   \u2022 {param}: {value}\")",
    "    print(f\"\\nMejor F1-Score (CV): {grid_lr.best_score_:.4f}\")",
    "",
    "# ==================",
    "# DECISION TREE - RANDOM SEARCH",
    "# ==================",
    "",
    "print(\"\\n\\n16.3 DECISION TREE - RANDOM SEARCH\")",
    "print(\"-\" * 80 + \"\\n\")",
    "",
    "from scipy.stats import randint",
    "",
    "param_dist_dt = {",
    "    'max_depth': randint(5, 30),",
    "    'min_samples_split': randint(50, 200),",
    "    'min_samples_leaf': randint(20, 100),",
    "    'criterion': ['gini', 'entropy']",
    "}",
    "",
    "print(\"Distribuci\u00f3n de par\u00e1metros:\")",
    "for param, dist in param_dist_dt.items():",
    "    print(f\"   \u2022 {param}: {dist}\")",
    "",
    "print(f\"\\nIteraciones: 20\")",
    "print(\"Ejecutando Random Search...\\n\")",
    "",
    "start_time = time()",
    "random_dt = RandomizedSearchCV(",
    "    DecisionTreeClassifier(random_state=RANDOM_STATE),",
    "    param_dist_dt,",
    "    n_iter=20,",
    "    cv=3,",
    "    scoring='f1_weighted',",
    "    random_state=RANDOM_STATE,",
    "    n_jobs=-1,",
    "    verbose=1",
    ")",
    "random_dt.fit(X_train, y_train)",
    "dt_tuning_time = time() - start_time",
    "",
    "tuned_models['Decision Tree (Tuned)'] = random_dt.best_estimator_",
    "best_params_dict['Decision Tree'] = random_dt.best_params_",
    "",
    "print(f\"\\n\u2705 Random Search completado en {dt_tuning_time:.2f}s\")",
    "print(f\"\\nMejores par\u00e1metros:\")",
    "for param, value in random_dt.best_params_.items():",
    "    print(f\"   \u2022 {param}: {value}\")",
    "print(f\"\\nMejor F1-Score (CV): {random_dt.best_score_:.4f}\")",
    "",
    "# ==================",
    "# COMPARACI\u00d3N: ANTES VS DESPU\u00c9S",
    "# ==================",
    "",
    "print(\"\\n\\n16.4 COMPARACI\u00d3N: MODELOS ORIGINALES VS OPTIMIZADOS\")",
    "print(\"-\" * 80 + \"\\n\")",
    "",
    "comparison_results = []",
    "",
    "for model_name in best_params_dict.keys():",
    "    # Modelo original",
    "    original_pred = predictions[model_name]",
    "    original_f1 = f1_score(y_test, original_pred, average='weighted')",
    "    original_acc = accuracy_score(y_test, original_pred)",
    "    ",
    "    # Modelo optimizado",
    "    tuned_model = tuned_models[f'{model_name} (Tuned)']",
    "    tuned_pred = tuned_model.predict(X_test)",
    "    tuned_f1 = f1_score(y_test, tuned_pred, average='weighted')",
    "    tuned_acc = accuracy_score(y_test, tuned_pred)",
    "    ",
    "    comparison_results.append({",
    "        'Modelo': model_name,",
    "        'F1 (Original)': original_f1,",
    "        'F1 (Tuned)': tuned_f1,",
    "        'F1 Mejora': tuned_f1 - original_f1,",
    "        'Acc (Original)': original_acc,",
    "        'Acc (Tuned)': tuned_acc,",
    "        'Acc Mejora': tuned_acc - original_acc",
    "    })",
    "",
    "comparison_df = pd.DataFrame(comparison_results)",
    "print(comparison_df.to_string(index=False))",
    "",
    "# Visualizaci\u00f3n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))",
    "",
    "# F1-Score comparison",
    "x = np.arange(len(comparison_df))",
    "width = 0.35",
    "",
    "axes[0].bar(x - width/2, comparison_df['F1 (Original)'], width, label='Original', alpha=0.8)",
    "axes[0].bar(x + width/2, comparison_df['F1 (Tuned)'], width, label='Optimizado', alpha=0.8)",
    "axes[0].set_xlabel('Modelo', fontweight='bold')",
    "axes[0].set_ylabel('F1-Score', fontweight='bold')",
    "axes[0].set_title('Comparaci\u00f3n F1-Score: Original vs Optimizado', fontsize=13, fontweight='bold')",
    "axes[0].set_xticks(x)",
    "axes[0].set_xticklabels(comparison_df['Modelo'], rotation=45, ha='right')",
    "axes[0].legend()",
    "axes[0].grid(axis='y', alpha=0.3)",
    "",
    "# Accuracy comparison",
    "axes[1].bar(x - width/2, comparison_df['Acc (Original)'], width, label='Original', alpha=0.8)",
    "axes[1].bar(x + width/2, comparison_df['Acc (Tuned)'], width, label='Optimizado', alpha=0.8)",
    "axes[1].set_xlabel('Modelo', fontweight='bold')",
    "axes[1].set_ylabel('Accuracy', fontweight='bold')",
    "axes[1].set_title('Comparaci\u00f3n Accuracy: Original vs Optimizado', fontsize=13, fontweight='bold')",
    "axes[1].set_xticks(x)",
    "axes[1].set_xticklabels(comparison_df['Modelo'], rotation=45, ha='right')",
    "axes[1].legend()",
    "axes[1].grid(axis='y', alpha=0.3)",
    "",
    "plt.tight_layout()",
    "plt.savefig('hyperparameter_tuning_comparison.png', dpi=300, bbox_inches='tight')",
    "plt.show()",
    "",
    "# Guardar modelos optimizados",
    "with open('tuned_models.pkl', 'wb') as f:",
    "    pickle.dump({",
    "        'models': tuned_models,",
    "        'best_params': best_params_dict",
    "    }, f)",
    "",
    "print(\"\\n\ud83d\udcbe Modelos optimizados guardados: tuned_models.pkl\")",
    "",
    "print(\"\\n\" + \"=\"*80)",
    "print(\"\u2705 TAREA 16 COMPLETADA\")",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================",
    "# TAREA 17: INTERPRETACI\u00d3N DE FEATURE IMPORTANCE",
    "# ============================================",
    "",
    "print(\"\\n\\n\" + \"=\"*80)",
    "print(\"TAREA 17: INTERPRETACI\u00d3N Y AN\u00c1LISIS DE FEATURE IMPORTANCE\")",
    "print(\"=\"*80 + \"\\n\")",
    "",
    "\"\"\"",
    "Analizaremos la importancia de las variables seg\u00fan diferentes modelos:",
    "- Random Forest: Feature Importance basado en reducci\u00f3n de impureza",
    "- Logistic Regression: Coeficientes del modelo",
    "- Decision Tree: Feature Importance basado en splits",
    "\"\"\"",
    "",
    "# ==================",
    "# 17.1: RANDOM FOREST FEATURE IMPORTANCE",
    "# ==================",
    "",
    "print(\"17.1 RANDOM FOREST - FEATURE IMPORTANCE\")",
    "print(\"-\" * 80 + \"\\n\")",
    "",
    "# Usar modelo optimizado si existe, sino el original",
    "rf_for_importance = tuned_models.get('Random Forest (Tuned)', models.get('Random Forest'))",
    "",
    "if rf_for_importance:",
    "    # Obtener importancias",
    "    importances_rf = rf_for_importance.feature_importances_",
    "    feature_names = X_train.columns",
    "    ",
    "    # Crear DataFrame",
    "    importance_df_rf = pd.DataFrame({",
    "        'Feature': feature_names,",
    "        'Importance': importances_rf",
    "    }).sort_values('Importance', ascending=False)",
    "    ",
    "    print(\"Top 10 Features m\u00e1s importantes:\\n\")",
    "    print(importance_df_rf.head(10).to_string(index=False))",
    "    ",
    "    # Visualizaci\u00f3n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))",
    "    ",
    "    # Top 15 features",
    "    top_n = 15",
    "    top_features = importance_df_rf.head(top_n)",
    "    ",
    "    axes[0].barh(range(top_n), top_features['Importance'].values, color='forestgreen', alpha=0.7)",
    "    axes[0].set_yticks(range(top_n))",
    "    axes[0].set_yticklabels(top_features['Feature'].values)",
    "    axes[0].invert_yaxis()",
    "    axes[0].set_xlabel('Importance', fontweight='bold')",
    "    axes[0].set_title(f'Top {top_n} Features - Random Forest', fontsize=13, fontweight='bold')",
    "    axes[0].grid(axis='x', alpha=0.3)",
    "    ",
    "    # Importancia acumulada",
    "    cumsum_importance = np.cumsum(importance_df_rf['Importance'].values)",
    "    axes[1].plot(range(1, len(cumsum_importance)+1), cumsum_importance, 'b-', linewidth=2)",
    "    axes[1].axhline(y=0.9, color='r', linestyle='--', label='90% threshold')",
    "    axes[1].axhline(y=0.95, color='orange', linestyle='--', label='95% threshold')",
    "    axes[1].set_xlabel('N\u00famero de Features', fontweight='bold')",
    "    axes[1].set_ylabel('Importancia Acumulada', fontweight='bold')",
    "    axes[1].set_title('Importancia Acumulada de Features', fontsize=13, fontweight='bold')",
    "    axes[1].legend()",
    "    axes[1].grid(alpha=0.3)",
    "    ",
    "    # Calcular cu\u00e1ntas features explican 90% y 95%",
    "    n_features_90 = np.argmax(cumsum_importance >= 0.90) + 1",
    "    n_features_95 = np.argmax(cumsum_importance >= 0.95) + 1",
    "    ",
    "    axes[1].axvline(x=n_features_90, color='r', linestyle=':', alpha=0.7)",
    "    axes[1].axvline(x=n_features_95, color='orange', linestyle=':', alpha=0.7)",
    "    ",
    "    plt.tight_layout()",
    "    plt.savefig('feature_importance_random_forest.png', dpi=300, bbox_inches='tight')",
    "    plt.show()",
    "    ",
    "    print(f\"\\n\ud83d\udcca Features necesarias para explicar:\")",
    "    print(f\"   \u2022 90% de la importancia: {n_features_90} features\")",
    "    print(f\"   \u2022 95% de la importancia: {n_features_95} features\")",
    "",
    "# ==================",
    "# 17.2: LOGISTIC REGRESSION COEFFICIENTS",
    "# ==================",
    "",
    "print(\"\\n\\n17.2 LOGISTIC REGRESSION - COEFICIENTES\")",
    "print(\"-\" * 80 + \"\\n\")",
    "",
    "lr_for_coef = tuned_models.get('Logistic Regression (Tuned)', models.get('Logistic Regression'))",
    "",
    "if lr_for_coef:",
    "    # Obtener coeficientes (promedio absoluto para todas las clases)",
    "    coef_abs = np.abs(lr_for_coef.coef_).mean(axis=0)",
    "    feature_names = X_train.columns",
    "    ",
    "    coef_df = pd.DataFrame({",
    "        'Feature': feature_names,",
    "        'Coef (abs mean)': coef_abs",
    "    }).sort_values('Coef (abs mean)', ascending=False)",
    "    ",
    "    print(\"Top 10 Features con mayor coeficiente:\\n\")",
    "    print(coef_df.head(10).to_string(index=False))",
    "    ",
    "    # Visualizaci\u00f3n detallada por clase",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))",
    "    axes = axes.ravel()",
    "    ",
    "    for idx, class_name in enumerate(le_target.classes_):",
    "        if idx < 5:  # Tenemos 5 clases",
    "            class_coef = lr_for_coef.coef_[idx]",
    "            coef_class_df = pd.DataFrame({",
    "                'Feature': feature_names,",
    "                'Coefficient': class_coef",
    "            }).sort_values('Coefficient', key=lambda x: abs(x), ascending=False).head(10)",
    "            ",
    "            colors = ['green' if x > 0 else 'red' for x in coef_class_df['Coefficient']]",
    "            axes[idx].barh(range(10), coef_class_df['Coefficient'].values, color=colors, alpha=0.7)",
    "            axes[idx].set_yticks(range(10))",
    "            axes[idx].set_yticklabels(coef_class_df['Feature'].values, fontsize=8)",
    "            axes[idx].invert_yaxis()",
    "            axes[idx].set_xlabel('Coeficiente', fontweight='bold')",
    "            axes[idx].set_title(f'Top 10 Coeficientes - Clase {class_name}', fontsize=11, fontweight='bold')",
    "            axes[idx].axvline(x=0, color='black', linestyle='-', linewidth=0.5)",
    "            axes[idx].grid(axis='x', alpha=0.3)",
    "    ",
    "    # Hide last subplot",
    "    axes[5].axis('off')",
    "    ",
    "    plt.tight_layout()",
    "    plt.savefig('feature_coefficients_logistic.png', dpi=300, bbox_inches='tight')",
    "    plt.show()",
    "    ",
    "    print(\"\\n\ud83d\udca1 Interpretaci\u00f3n:\")",
    "    print(\"   \u2022 Coeficientes positivos: Aumentan probabilidad de la clase\")",
    "    print(\"   \u2022 Coeficientes negativos: Disminuyen probabilidad de la clase\")",
    "    print(\"   \u2022 Mayor magnitud: Mayor influencia en la predicci\u00f3n\")",
    "",
    "# ==================",
    "# 17.3: DECISION TREE FEATURE IMPORTANCE",
    "# ==================",
    "",
    "print(\"\\n\\n17.3 DECISION TREE - FEATURE IMPORTANCE\")",
    "print(\"-\" * 80 + \"\\n\")",
    "",
    "dt_for_importance = tuned_models.get('Decision Tree (Tuned)', models.get('Decision Tree'))",
    "",
    "if dt_for_importance:",
    "    importances_dt = dt_for_importance.feature_importances_",
    "    ",
    "    importance_df_dt = pd.DataFrame({",
    "        'Feature': X_train.columns,",
    "        'Importance': importances_dt",
    "    }).sort_values('Importance', ascending=False)",
    "    ",
    "    print(\"Top 10 Features m\u00e1s importantes:\\n\")",
    "    print(importance_df_dt.head(10).to_string(index=False))",
    "    ",
    "    # Visualizaci\u00f3n del \u00e1rbol (top levels)",
    "    fig, ax = plt.subplots(figsize=(20, 10))",
    "    plot_tree(dt_for_importance, ",
    "              feature_names=X_train.columns,",
    "              class_names=le_target.classes_,",
    "              filled=True,",
    "              rounded=True,",
    "              max_depth=3,  # Solo primeros 3 niveles para legibilidad",
    "              fontsize=10,",
    "              ax=ax)",
    "    plt.title('Estructura del \u00c1rbol de Decisi\u00f3n (3 primeros niveles)', ",
    "              fontsize=15, fontweight='bold')",
    "    plt.tight_layout()",
    "    plt.savefig('decision_tree_structure.png', dpi=300, bbox_inches='tight')",
    "    plt.show()",
    "",
    "# ==================",
    "# 17.4: COMPARACI\u00d3N DE IMPORTANCIAS",
    "# ==================",
    "",
    "print(\"\\n\\n17.4 COMPARACI\u00d3N DE IMPORTANCIAS ENTRE MODELOS\")",
    "print(\"-\" * 80 + \"\\n\")",
    "",
    "# Crear DataFrame comparativo",
    "comparison_importance = pd.DataFrame({",
    "    'Feature': X_train.columns",
    "})",
    "",
    "if rf_for_importance:",
    "    comparison_importance['RF Importance'] = importances_rf",
    "",
    "if lr_for_coef:",
    "    comparison_importance['LR Coef (abs)'] = coef_abs",
    "",
    "if dt_for_importance:",
    "    comparison_importance['DT Importance'] = importances_dt",
    "",
    "# Normalizar para comparaci\u00f3n",
    "for col in comparison_importance.columns[1:]:",
    "    comparison_importance[col + ' (norm)'] = (",
    "        comparison_importance[col] / comparison_importance[col].sum()",
    "    )",
    "",
    "# Top features consenso",
    "norm_cols = [c for c in comparison_importance.columns if '(norm)' in c]",
    "comparison_importance['Mean Importance'] = comparison_importance[norm_cols].mean(axis=1)",
    "comparison_importance = comparison_importance.sort_values('Mean Importance', ascending=False)",
    "",
    "print(\"Top 15 Features seg\u00fan consenso de modelos:\\n\")",
    "print(comparison_importance[['Feature', 'Mean Importance']].head(15).to_string(index=False))",
    "",
    "# Visualizaci\u00f3n",
    "fig, ax = plt.subplots(figsize=(14, 8))",
    "top_15_consensus = comparison_importance.head(15)",
    "",
    "x = np.arange(15)",
    "width = 0.25",
    "",
    "if 'RF Importance (norm)' in top_15_consensus.columns:",
    "    ax.bar(x - width, top_15_consensus['RF Importance (norm)'], width, ",
    "           label='Random Forest', alpha=0.8)",
    "",
    "if 'LR Coef (abs) (norm)' in top_15_consensus.columns:",
    "    ax.bar(x, top_15_consensus['LR Coef (abs) (norm)'], width, ",
    "           label='Logistic Regression', alpha=0.8)",
    "",
    "if 'DT Importance (norm)' in top_15_consensus.columns:",
    "    ax.bar(x + width, top_15_consensus['DT Importance (norm)'], width, ",
    "           label='Decision Tree', alpha=0.8)",
    "",
    "ax.set_xlabel('Features', fontweight='bold')",
    "ax.set_ylabel('Importancia Normalizada', fontweight='bold')",
    "ax.set_title('Comparaci\u00f3n de Feature Importance entre Modelos', ",
    "             fontsize=14, fontweight='bold')",
    "ax.set_xticks(x)",
    "ax.set_xticklabels(top_15_consensus['Feature'], rotation=45, ha='right')",
    "ax.legend()",
    "ax.grid(axis='y', alpha=0.3)",
    "",
    "plt.tight_layout()",
    "plt.savefig('feature_importance_comparison.png', dpi=300, bbox_inches='tight')",
    "plt.show()",
    "",
    "# Guardar resultados",
    "feature_importance_results = {",
    "    'random_forest': importance_df_rf.to_dict() if rf_for_importance else None,",
    "    'logistic_regression': coef_df.to_dict() if lr_for_coef else None,",
    "    'decision_tree': importance_df_dt.to_dict() if dt_for_importance else None,",
    "    'consensus': comparison_importance.to_dict()",
    "}",
    "",
    "with open('feature_importance_analysis.pkl', 'wb') as f:",
    "    pickle.dump(feature_importance_results, f)",
    "",
    "print(\"\\n\ud83d\udcbe An\u00e1lisis de importancia guardado: feature_importance_analysis.pkl\")",
    "",
    "print(\"\\n\" + \"=\"*80)",
    "print(\"\u2705 TAREA 17 COMPLETADA\")",
    "print(\"=\"*80)",
    "",
    "print(\"\\n\ud83d\udca1 HALLAZGOS CLAVE:\")",
    "print(\"   \u2022 Las features m\u00e1s importantes son consistentes entre modelos\")",
    "print(\"   \u2022 Pocas features explican la mayor parte de la varianza\")",
    "print(\"   \u2022 Los coeficientes revelan relaciones direccionales con las clases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================",
    "# RESUMEN FINAL DE LA SECCI\u00d3N 4",
    "# ============================================",
    "",
    "print(\"\\n\\n\" + \"=\"*80)",
    "print(\"\ud83d\udcca RESUMEN SECCI\u00d3N 4: APRENDIZAJE SUPERVISADO\")",
    "print(\"=\"*80 + \"\\n\")",
    "",
    "summary_text = f\"\"\"",
    "\u2705 APRENDIZAJE SUPERVISADO COMPLETADO",
    "",
    "TAREA 13: Entrenamiento de Modelos",
    "   \u2022 Modelos entrenados: {len(models)}",
    "   \u2022 Algoritmos: Decision Tree, Random Forest, Logistic Regression, SVM, KNN",
    "   \u2022 Tiempo total de entrenamiento: {sum(training_times.values()):.2f}s",
    "",
    "TAREA 14: Comparaci\u00f3n y Evaluaci\u00f3n",
    "   \u2022 Mejor modelo (F1-Score): {metrics_df.index[0]}",
    "   \u2022 F1-Score m\u00e1ximo: {metrics_df['F1-Score'].max():.4f}",
    "   \u2022 Accuracy m\u00e1ximo: {metrics_df['Accuracy'].max():.4f}",
    "   \u2022 M\u00e9tricas calculadas: Accuracy, Precision, Recall, F1-Score",
    "   \u2022 Matrices de confusi\u00f3n generadas para todos los modelos",
    "",
    "TAREA 15: Validaci\u00f3n Cruzada",
    "   \u2022 M\u00e9todo: {N_FOLDS}-Fold Stratified Cross-Validation",
    "   \u2022 Modelo m\u00e1s estable: {cv_summary_df.iloc[0]['Modelo']}",
    "   \u2022 Menor desviaci\u00f3n est\u00e1ndar: {cv_summary_df['Accuracy (std)'].min():.5f}",
    "   \u2022 An\u00e1lisis de overfitting realizado",
    "",
    "TAREA 16: Ajuste de Hiperpar\u00e1metros",
    "   \u2022 Modelos optimizados: {len(tuned_models)}",
    "   \u2022 M\u00e9todos: Grid Search y Random Search",
    "   \u2022 Mejora promedio en F1-Score: {comparison_df['F1 Mejora'].mean():.4f}",
    "",
    "TAREA 17: Feature Importance",
    "   \u2022 Top features identificadas y consensuadas",
    "   \u2022 An\u00e1lisis de coeficientes de regresi\u00f3n log\u00edstica",
    "   \u2022 Estructura del \u00e1rbol de decisi\u00f3n visualizada",
    "   \u2022 Features para 90% de importancia: {n_features_90 if 'n_features_90' in locals() else 'N/A'}",
    "",
    "ARCHIVOS GENERADOS:",
    "   \u2713 model_comparison_metrics.png",
    "   \u2713 confusion_matrices.png",
    "   \u2713 cross_validation_analysis.png",
    "   \u2713 hyperparameter_tuning_comparison.png",
    "   \u2713 feature_importance_*.png",
    "   \u2713 tuned_models.pkl",
    "   \u2713 feature_importance_analysis.pkl",
    "",
    "CONCLUSIONES Y RECOMENDACIONES:",
    "",
    "1. RENDIMIENTO GENERAL:",
    "   Los modelos supervisados logran buenos resultados en la clasificaci\u00f3n del",
    "   nivel de ingl\u00e9s, con F1-Scores superiores a {metrics_df['F1-Score'].min():.2f}.",
    "",
    "2. MODELO RECOMENDADO:",
    "   {metrics_df.index[0]} muestra el mejor balance entre precisi\u00f3n,",
    "   estabilidad y tiempo de entrenamiento.",
    "",
    "3. DESAF\u00cdOS IDENTIFICADOS:",
    "   \u2022 Traslape entre clases intermedias (A1, A2, B1)",
    "   \u2022 Desbalance de clases afecta m\u00e9tricas de clases minoritarias",
    "   \u2022 Algunos modelos muestran signos leves de overfitting",
    "",
    "4. PR\u00d3XIMOS PASOS (Secci\u00f3n 5):",
    "   \u2022 Implementar t\u00e9cnicas de balanceo (SMOTE)",
    "   \u2022 Probar ensemble methods avanzados",
    "   \u2022 Feature engineering adicional",
    "   \u2022 Regularizaci\u00f3n para reducir overfitting",
    "",
    "PR\u00d3XIMA SECCI\u00d3N: Secci\u00f3n 5 - Evaluaci\u00f3n e Interpretaci\u00f3n",
    "\"\"\"",
    "",
    "print(summary_text)",
    "",
    "# Guardar resumen completo",
    "full_results = {",
    "    'models': models,",
    "    'tuned_models': tuned_models,",
    "    'predictions': predictions,",
    "    'metrics': metrics_results,",
    "    'cv_results': cv_results,",
    "    'best_params': best_params_dict,",
    "    'training_times': training_times",
    "}",
    "",
    "with open('seccion4_complete_results.pkl', 'wb') as f:",
    "    pickle.dump(full_results, f)",
    "",
    "with open('resumen_seccion4.txt', 'w', encoding='utf-8') as f:",
    "    f.write(\"RESUMEN SECCI\u00d3N 4: APRENDIZAJE SUPERVISADO\\n\")",
    "    f.write(\"=\"*80 + \"\\n\\n\")",
    "    f.write(summary_text)",
    "",
    "print(\"\\n\ud83d\udcbe Resumen guardado: resumen_seccion4.txt\")",
    "print(\"\ud83d\udcbe Resultados completos: seccion4_complete_results.pkl\")",
    "",
    "print(\"\\n\" + \"=\"*80)",
    "print(\"\ud83c\udf89 \u00a1SECCI\u00d3N 4 COMPLETADA EXITOSAMENTE!\")",
    "print(\"=\"*80)",
    "print(\"\\nEst\u00e1s listo para continuar con la Secci\u00f3n 5: Evaluaci\u00f3n e Interpretaci\u00f3n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}