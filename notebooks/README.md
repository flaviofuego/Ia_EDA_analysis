# üìì NOTEBOOKS DEL PROYECTO

Esta carpeta contiene los 6 notebooks principales del proyecto de Inteligencia Artificial, organizados por secciones correspondientes a las 25 tareas evaluables.

---

## üìö Notebooks por Secci√≥n

### üìä seccion1.ipynb - COMPRENSI√ìN DE DATOS
**Tareas 1-5** | **Duraci√≥n estimada**: 15-20 minutos

**Contenido:**
- **Tarea 1**: Descripci√≥n completa del dataset (fuente, dominio, variables, problema)
- **Tarea 2**: Formulaci√≥n de 6 hip√≥tesis de predicci√≥n
- **Tarea 3**: EDA completo (missing values, outliers, distribuciones)
  - ‚ú® **NUEVO**: Pruebas de normalidad (Shapiro-Wilk, KS, D'Agostino-Pearson)
  - ‚ú® **NUEVO**: An√°lisis de skewness y kurtosis
- **Tarea 4**: An√°lisis de correlaci√≥n/asociaci√≥n (Pearson, Spearman, Cram√©r's V)
  - ‚ú® **NUEVO**: An√°lisis de multicolinealidad (VIF)
- **Tarea 5**: Visualizaciones multivariadas (scatter, boxplots, heatmaps, pair plots)

**Outputs generados:**
- `outputs/seccion1/checkpoint_seccion1_completa.json`
- `outputs/seccion1/variables_seleccionadas.txt`
- `outputs/seccion1/normality_tests.png` ‚ú® NUEVO
- `outputs/seccion1/vif_analysis.png` ‚ú® NUEVO
- M√∫ltiples visualizaciones de EDA

---

### üîß seccion2.ipynb - PREPROCESAMIENTO
**Tareas 6-8** | **Duraci√≥n estimada**: 10-15 minutos

**Contenido:**
- **Tarea 6**: Tratamiento de datos faltantes, codificaci√≥n categ√≥ricas, normalizaci√≥n
- **Tarea 7**: Divisi√≥n train/test (70/30) estratificada
- **Tarea 8**: PCA con an√°lisis de varianza explicada

**Outputs generados:**
- `data/processed/X_train.csv`, `X_test.csv`
- `data/processed/y_train.csv`, `y_test.csv`
- `data/processed/preprocessing_objects.pkl`
- `data/processed/pca_models.pkl`
- Visualizaciones de PCA (scree plot, proyecciones 2D/3D)

---

### üîç seccion3.ipynb - APRENDIZAJE NO SUPERVISADO
**Tareas 9-12** | **Duraci√≥n estimada**: 15-20 minutos

**Contenido:**
- **Tarea 9**: Clustering (K-Means, DBSCAN, Jer√°rquico)
- **Tarea 10**: Determinaci√≥n de k √≥ptimo (m√©todo del codo, silueta)
- **Tarea 11**: Visualizaci√≥n de clusters 2D/3D y relaci√≥n con variable objetivo
- **Tarea 12**: Reducci√≥n dimensional no supervisada (PCA, t-SNE, UMAP)

**Outputs generados:**
- `outputs/seccion3/resumen_seccion3.txt`
- Visualizaciones de clusters
- M√©tricas de clustering (ARI, NMI, Silhouette)
- Proyecciones t-SNE y UMAP

---

### ü§ñ seccion4.ipynb - APRENDIZAJE SUPERVISADO
**Tareas 13-17** | **Duraci√≥n estimada**: 20-30 minutos

**Contenido:**
- **Tarea 13**: Entrenamiento de 5 modelos (Decision Tree, Random Forest, Logistic Regression, SVM, KNN)
- **Tarea 14**: Comparaci√≥n con m√©tricas completas
  - ‚ú® **NUEVO**: Curvas ROC-AUC multiclase (One-vs-Rest)
- **Tarea 15**: Validaci√≥n cruzada (5-fold) y an√°lisis de estabilidad
- **Tarea 16**: Grid Search para hiperpar√°metros
- **Tarea 17**: Feature importance y coeficientes

**Outputs generados:**
- `outputs/seccion4/*.png` (9 visualizaciones)
- `outputs/seccion4/roc_curves_multiclass.png` ‚ú® NUEVO
- `data/processed/modelos_entrenados.pkl`
- `data/processed/best_model.pkl`

---

### üìà seccion5.ipynb - EVALUACI√ìN E INTERPRETACI√ìN
**Tareas 18-20** | **Duraci√≥n estimada**: 15-20 minutos

**Contenido:**
- ‚ú® **NUEVA SUBSECCI√ìN 19.0**: Verificaci√≥n de data leakage (7 checks sistem√°ticos)
- **Tarea 18**: Comparaci√≥n supervisado vs no supervisado
- **Tarea 19**: Mejoras metodol√≥gicas
  - ‚ú® **NUEVO**: Comparaci√≥n de variantes de SMOTE (6 t√©cnicas)
  - Feature Engineering (PolynomialFeatures)
  - Ensemble Methods (Voting, Stacking)
  - ‚ú® **NUEVO**: Regularizaci√≥n L1/L2 y Early Stopping
  - Nuevas m√©tricas (Balanced Accuracy, Cohen's Kappa)
- **Tarea 20**: Discusi√≥n cr√≠tica y conclusiones

**Outputs generados:**
- `outputs/seccion5/*.png` (5 visualizaciones originales)
- `outputs/seccion5/smote_variants_comparison.png` ‚ú® NUEVO
- `outputs/seccion5/regularization_analysis.png` ‚ú® NUEVO
- `data/processed/modelo_mejorado.pkl`

---

### üíª seccion6.ipynb - IMPLEMENTACI√ìN EN C
**Tareas 21-25** | **Duraci√≥n estimada**: 15-20 minutos

**Contenido:**
- **Tarea 21**: Selecci√≥n y justificaci√≥n de algoritmo KNN
- **Tarea 22**: Dise√±o de estructuras y funciones (pseudoc√≥digo)
- ‚ú® **NUEVA CELDA**: Generaci√≥n autom√°tica de CSVs para C
- **Tarea 23**: Implementaci√≥n completa en C (701 l√≠neas) - Con Docker
- **Tarea 24**: Evaluaci√≥n y comparaci√≥n Python vs C
- **Tarea 25**: An√°lisis de limitaciones y optimizaciones

**Outputs generados:**
- `outputs/seccion6/*.txt` y `*.png` (8 archivos)
- `data/processed/train_data_c.csv` ‚ú® NUEVO
- `data/processed/test_data_c.csv` ‚ú® NUEVO

---

## üöÄ Orden de Ejecuci√≥n

**IMPORTANTE**: Ejecutar los notebooks en orden:

```
1. seccion1.ipynb  ‚Üí  Genera variables_seleccionadas.txt
2. seccion2.ipynb  ‚Üí  Usa variables de secci√≥n 1, genera train/test
3. seccion3.ipynb  ‚Üí  Usa datos de secci√≥n 2
4. seccion4.ipynb  ‚Üí  Usa datos de secci√≥n 2
5. seccion5.ipynb  ‚Üí  Usa modelos de secci√≥n 4
6. seccion6.ipynb  ‚Üí  Genera CSVs y ejecuta c√≥digo C
```

---

## ‚öôÔ∏è Configuraci√≥n Global

**Par√°metros consistentes en todos los notebooks:**
```python
RANDOM_STATE = 42
TARGET_COLUMN = 'DESEMP_INGLES'
TEST_SIZE = 0.30
CV_FOLDS = 5
```

---

## üì¶ Dependencias

**Librer√≠as requeridas:**
```bash
pip install pandas numpy matplotlib seaborn scikit-learn scipy \
            imbalanced-learn xgboost umap-learn plotly statsmodels
```

**Versiones recomendadas:**
- Python: 3.8+
- pandas: 1.3+
- scikit-learn: 1.0+
- numpy: 1.21+

---

## üé® Visualizaciones por Notebook

| Notebook | Visualizaciones Generadas | Total |
|----------|--------------------------|-------|
| Secci√≥n 1 | ~15 (EDA, correlaciones, normalidad, VIF) | 15+ |
| Secci√≥n 2 | ~3 (PCA) | 3 |
| Secci√≥n 3 | ~8 (clustering, reducci√≥n) | 8 |
| Secci√≥n 4 | ~9 (modelos, m√©tricas, ROC-AUC) | 9 |
| Secci√≥n 5 | ~8 (comparaciones, mejoras) | 8 |
| Secci√≥n 6 | ~4 (comparaci√≥n C vs Python) | 4 |
| **TOTAL** | | **47+** |

---

## ‚ú® Nuevas Caracter√≠sticas (Correcciones Implementadas)

Las siguientes caracter√≠sticas fueron agregadas en las correcciones:

### Secci√≥n 1:
- ‚úÖ Subsecci√≥n 3.4: Pruebas de normalidad (Shapiro-Wilk, KS, D'Agostino)
- ‚úÖ Subsecci√≥n 4.5: An√°lisis VIF para multicolinealidad

### Secci√≥n 4:
- ‚úÖ Subsecci√≥n 14.5: Curvas ROC-AUC multiclase (grid 2√ó3)

### Secci√≥n 5:
- ‚úÖ Subsecci√≥n 19.0: Verificaci√≥n de data leakage (7 checks)
- ‚úÖ Subsecci√≥n 19.2: Comparaci√≥n SMOTE variants (reemplaza SMOTE b√°sico)
- ‚úÖ Subsecci√≥n 19.4: Regularizaci√≥n L1/L2 y Early Stopping

### Secci√≥n 6:
- ‚úÖ Nueva celda: Generaci√≥n autom√°tica de CSVs para C

**Total de l√≠neas a√±adidas**: ~750 l√≠neas de c√≥digo production-ready

---

## üìù Notas de Ejecuci√≥n

### Tiempo Total Estimado
- **Ejecuci√≥n completa**: ~90-120 minutos
- **Por secci√≥n**: 10-30 minutos

### Recursos Requeridos
- **RAM**: 8GB m√≠nimo, 16GB recomendado
- **Disco**: ~5GB para datasets y outputs
- **CPU**: Multicore recomendado para modelos

### Reproducibilidad
- Todos los notebooks usan `random_state=42`
- Resultados son 100% reproducibles
- Outputs id√©nticos en cada ejecuci√≥n

---

## üêõ Soluci√≥n de Problemas

### Problema: "FileNotFoundError: dataset_saber11_reducido_estratificado.csv"
**Soluci√≥n**:
```python
# Actualizar ruta en el notebook
df = pd.read_csv('../data/raw/dataset_saber11_reducido_estratificado.xlsx')
```

### Problema: "ImportError: No module named 'imbalanced-learn'"
**Soluci√≥n**:
```bash
pip install imbalanced-learn
```

### Problema: C√≥digo muy lento
**Soluci√≥n**:
```python
# Usar subconjunto para pruebas
df = df.sample(n=10000, random_state=42)
```

---

## üìö Documentaci√≥n Adicional

- Ver `outputs/` para archivos generados por cada secci√≥n
- Ver `docs/quick-starts/` para gu√≠as r√°pidas
- Ver `docs/reportes/` para an√°lisis completo del proyecto

---

**Generado autom√°ticamente - Proyecto IA Universidad del Norte**
