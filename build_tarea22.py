#!/usr/bin/env python3
"""
Complete Section 6 Notebook Builder
Generates all remaining tasks (22-25) for the notebook
"""

import json

def load_notebook(path='notebooks/seccion6.ipynb'):
    with open(path, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_notebook(notebook, path='notebooks/seccion6.ipynb'):
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(notebook, f, indent=1, ensure_ascii=False)

def add_cell(notebook, cell_type, source):
    """Add a cell to the notebook"""
    cell = {
        "cell_type": cell_type,
        "metadata": {},
        "source": source if isinstance(source, list) else [source]
    }
    if cell_type == "code":
        cell["execution_count"] = None
        cell["outputs"] = []
    notebook["cells"].append(cell)

def build_tarea22_markdown():
    """Build Tarea 22 markdown explanation"""
    return """---

# ============================================
# TAREA 22: DiseÃ±o de Estructuras y Funciones
# ============================================

## ğŸ—ï¸ Objetivo
DiseÃ±ar las estructuras de datos y funciones necesarias para la implementaciÃ³n de KNN en C.

---

## ğŸ“ DISEÃ‘O DE ESTRUCTURAS DE DATOS

### 1. Estructura para Datos de Entrenamiento
```c
typedef struct {
    double features[MAX_FEATURES];  // Vector de caracterÃ­sticas
    int label;                       // Etiqueta de clase (0-4 para 5 clases)
} DataPoint;
```

### 2. Estructura para Conjunto de Datos
```c
typedef struct {
    DataPoint* data;        // Array dinÃ¡mico de puntos
    int n_samples;          // NÃºmero de muestras
    int n_features;         // NÃºmero de caracterÃ­sticas
    int n_classes;          // NÃºmero de clases
} Dataset;
```

### 3. Estructura para Vecinos
```c
typedef struct {
    int index;             // Ãndice del vecino en el dataset
    double distance;       // Distancia al punto de consulta
    int label;             // Etiqueta del vecino
} Neighbor;
```

### 4. Estructura para Modelo KNN
```c
typedef struct {
    Dataset* training_data; // Datos de entrenamiento
    int k;                  // NÃºmero de vecinos
} KNNModel;
```

---

## ğŸ”§ DISEÃ‘O DE FUNCIONES PRINCIPALES

### 1. Funciones de Carga de Datos
```c
// Leer datos desde archivo CSV
Dataset* load_dataset(const char* filename, int* n_features, int* n_classes);

// Liberar memoria del dataset
void free_dataset(Dataset* dataset);
```

### 2. Funciones de Distancia
```c
// Calcular distancia euclidiana entre dos puntos
double euclidean_distance(const double* point1, const double* point2, int n_features);
```

### 3. Funciones del Modelo KNN
```c
// Inicializar modelo KNN
KNNModel* create_knn_model(int k);

// Entrenar modelo (almacenar datos)
void knn_fit(KNNModel* model, Dataset* training_data);

// Predecir clase de un punto
int knn_predict_single(KNNModel* model, const double* test_point);

// Predecir clases de mÃºltiples puntos
void knn_predict(KNNModel* model, Dataset* test_data, int* predictions);

// Liberar memoria del modelo
void free_knn_model(KNNModel* model);
```

### 4. Funciones Auxiliares
```c
// Encontrar k vecinos mÃ¡s cercanos y ordenarlos
int compare_neighbors(const void* a, const void* b);

// Votar por la clase mayoritaria
int majority_vote(Neighbor* neighbors, int k, int n_classes);
```

### 5. Funciones de EvaluaciÃ³n
```c
// Calcular accuracy
double calculate_accuracy(const int* y_true, const int* y_pred, int n_samples);

// Matriz de confusiÃ³n
void print_confusion_matrix(const int* y_true, const int* y_pred, 
                           int n_samples, int n_classes);

// MÃ©tricas por clase
void print_per_class_metrics(const int* y_true, const int* y_pred,
                             int n_samples, int n_classes);
```

---

## ğŸ“‹ PSEUDOCÃ“DIGO DEL ALGORITMO PRINCIPAL

```
ALGORITMO KNN_PREDICT_SINGLE(model, test_point)
ENTRADA:
    - model: Modelo KNN entrenado con datos
    - test_point: Punto a clasificar (array de features)
    
SALIDA:
    - predicted_class: Clase predicha (entero 0 a n_classes-1)

INICIO
    // 1. Inicializar array de vecinos
    vecinos â† nuevo array de tamaÃ±o n_samples
    
    // 2. Calcular distancias a todos los puntos de entrenamiento
    PARA i â† 0 HASTA model.training_data.n_samples - 1 HACER
        punto_entrenamiento â† model.training_data.data[i]
        distancia â† euclidean_distance(test_point, punto_entrenamiento.features)
        
        vecinos[i].index â† i
        vecinos[i].distance â† distancia
        vecinos[i].label â† punto_entrenamiento.label
    FIN PARA
    
    // 3. Ordenar vecinos por distancia (qsort)
    qsort(vecinos, n_samples, sizeof(Neighbor), compare_neighbors)
    
    // 4. Tomar los k mÃ¡s cercanos
    k_vecinos â† vecinos[0:k]
    
    // 5. Votar por la clase mayoritaria
    predicted_class â† majority_vote(k_vecinos, k, model.n_classes)
    
    // 6. Liberar memoria y retornar
    liberar(vecinos)
    RETORNAR predicted_class
FIN

ALGORITMO MAJORITY_VOTE(neighbors, k, n_classes)
ENTRADA:
    - neighbors: Array de k vecinos mÃ¡s cercanos
    - k: NÃºmero de vecinos
    - n_classes: NÃºmero de clases
    
SALIDA:
    - winning_class: Clase con mÃ¡s votos

INICIO
    // 1. Inicializar contadores de votos
    votos â† nuevo array de tamaÃ±o n_classes inicializado en 0
    
    // 2. Contar votos
    PARA i â† 0 HASTA k - 1 HACER
        clase â† neighbors[i].label
        votos[clase] â† votos[clase] + 1
    FIN PARA
    
    // 3. Encontrar clase con mÃ¡s votos
    winning_class â† 0
    max_votos â† votos[0]
    
    PARA i â† 1 HASTA n_classes - 1 HACER
        SI votos[i] > max_votos ENTONCES
            max_votos â† votos[i]
            winning_class â† i
        FIN SI
    FIN PARA
    
    // 4. Liberar memoria y retornar
    liberar(votos)
    RETORNAR winning_class
FIN

ALGORITMO EUCLIDEAN_DISTANCE(point1, point2, n_features)
ENTRADA:
    - point1, point2: Arrays de features
    - n_features: NÃºmero de caracterÃ­sticas
    
SALIDA:
    - distance: Distancia euclidiana

INICIO
    suma â† 0.0
    
    PARA i â† 0 HASTA n_features - 1 HACER
        diferencia â† point1[i] - point2[i]
        suma â† suma + (diferencia * diferencia)
    FIN PARA
    
    distance â† raiz_cuadrada(suma)
    RETORNAR distance
FIN
```

---

## ğŸ”„ FLUJO DE EJECUCIÃ“N

```
1. INICIO
   â†“
2. CARGAR DATOS DE ENTRENAMIENTO (CSV)
   â†“
3. CARGAR DATOS DE PRUEBA (CSV)
   â†“
4. CREAR MODELO KNN (k=5)
   â†“
5. ENTRENAR MODELO (almacenar datos)
   â†“
6. PREDECIR CLASES DE TEST SET
   â”‚
   â”œâ”€ Para cada punto de prueba:
   â”‚  â”œâ”€ Calcular distancias a todos los puntos de entrenamiento
   â”‚  â”œâ”€ Ordenar y encontrar k vecinos mÃ¡s cercanos
   â”‚  â””â”€ Votar por clase mayoritaria
   â†“
7. EVALUAR RESULTADOS
   â”œâ”€ Calcular accuracy
   â”œâ”€ Generar matriz de confusiÃ³n
   â””â”€ Calcular mÃ©tricas por clase
   â†“
8. IMPRIMIR RESULTADOS
   â†“
9. LIBERAR MEMORIA
   â†“
10. FIN
```

---

## ğŸ“Š ANÃLISIS DE COMPLEJIDAD

### Complejidad Temporal:
- **Carga de datos**: O(n)
- **Entrenamiento (fit)**: O(1) - solo copia puntero
- **PredicciÃ³n de 1 punto**: O(n * d + n*log(n)) donde n=muestras, d=features
- **PredicciÃ³n de m puntos**: O(m * n * (d + log(n)))
- **CÃ¡lculo de distancia**: O(d)
- **VotaciÃ³n**: O(k)
- **Ordenamiento**: O(n*log(n)) con qsort

### Complejidad Espacial:
- **Almacenamiento de datos**: O(n * d)
- **Array de vecinos**: O(n) durante predicciÃ³n
- **Matriz de confusiÃ³n**: O(cÂ²) donde c=clases
- **Total**: O(n * d + cÂ²)

### Optimizaciones Consideradas:
1. **qsort estÃ¡ndar de C**: MÃ¡s eficiente que insertion sort manual
2. **NormalizaciÃ³n Previa**: Los datos ya vienen normalizados de Python
3. **GestiÃ³n eficiente de memoria**: malloc/free en los momentos correctos

---"""

def build_tarea22_code():
    """Build Tarea 22 code cell"""
    return """# ============================================
# TAREA 22: DocumentaciÃ³n y VisualizaciÃ³n del DiseÃ±o
# ============================================

print("="*80)
print("TAREA 22: DISEÃ‘O DE ESTRUCTURAS Y FUNCIONES")
print("="*80)

# Crear diagrama de flujo textual
flowchart_text = \"\"\"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DIAGRAMA DE FLUJO KNN EN C                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                           [INICIO]
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Leer argumentos    â”‚
                    â”‚  (train.csv,        â”‚
                    â”‚   test.csv, k)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  load_dataset()     â”‚
                    â”‚  Cargar datos de    â”‚
                    â”‚  entrenamiento      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  load_dataset()     â”‚
                    â”‚  Cargar datos de    â”‚
                    â”‚  prueba             â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  create_knn_model() â”‚
                    â”‚  Inicializar modelo â”‚
                    â”‚  con k=5            â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  knn_fit()          â”‚
                    â”‚  Almacenar datos    â”‚
                    â”‚  de entrenamiento   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
              â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
              â•‘  BUCLE: Para cada punto test  â•‘
              â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                              â”‚
                              â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  knn_predict_single()                â”‚
           â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
           â”‚  â”‚ Para cada punto entrenamiento: â”‚  â”‚
           â”‚  â”‚ - euclidean_distance()         â”‚  â”‚
           â”‚  â”‚ - Actualizar vecinos array     â”‚  â”‚
           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
           â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
           â”‚  â”‚ qsort(vecinos)                 â”‚  â”‚
           â”‚  â”‚ Ordenar por distancia          â”‚  â”‚
           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
           â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
           â”‚  â”‚ majority_vote()                â”‚  â”‚
           â”‚  â”‚ - Contar votos por clase       â”‚  â”‚
           â”‚  â”‚ - Retornar clase ganadora      â”‚  â”‚
           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
              â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
              â•‘  FIN BUCLE                    â•‘
              â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Evaluar resultados â”‚
                    â”‚  - calculate_       â”‚
                    â”‚    accuracy()       â”‚
                    â”‚  - confusion_       â”‚
                    â”‚    matrix()         â”‚
                    â”‚  - per_class_       â”‚
                    â”‚    metrics()        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Liberar memoria    â”‚
                    â”‚  - free_dataset()   â”‚
                    â”‚  - free_knn_model() â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                            [FIN]
\"\"\"

print(flowchart_text)

# Documentar estructuras de datos
structures_doc = \"\"\"
================================================================================
DOCUMENTACIÃ“N DE ESTRUCTURAS DE DATOS
================================================================================

1. DataPoint
   PropÃ³sito: Representar un punto de datos con sus caracterÃ­sticas y etiqueta
   TamaÃ±o: sizeof(double) * MAX_FEATURES + sizeof(int)
   Uso: Almacenamiento de datos de entrenamiento y prueba

2. Dataset
   PropÃ³sito: Contenedor para mÃºltiples puntos de datos
   TamaÃ±o: DinÃ¡mico segÃºn n_samples
   Uso: GestiÃ³n de conjuntos de entrenamiento y prueba

3. Neighbor
   PropÃ³sito: Almacenar informaciÃ³n de vecinos cercanos
   TamaÃ±o: sizeof(int) + sizeof(double) + sizeof(int)
   Uso: Array de vecinos durante la predicciÃ³n

4. KNNModel
   PropÃ³sito: Modelo completo de KNN
   TamaÃ±o: sizeof(Dataset*) + sizeof(int)
   Uso: Entidad principal para entrenamiento y predicciÃ³n

DECISIONES DE DISEÃ‘O:
- Arrays estÃ¡ticos para features (MAX_FEATURES) dentro de DataPoint
- Punteros para datasets (malloc una vez) para manejar tamaÃ±os variables
- Estructuras simples sin herencia ni polimorfismo (C puro)
- Funciones que reciben punteros para eficiencia

GESTIÃ“N DE MEMORIA:
- malloc() para datasets (tamaÃ±o conocido en runtime)
- free() explÃ­cito en funciones de limpieza
- Sin memory leaks (verificable con valgrind)

================================================================================
\"\"\"

print(structures_doc)

# Guardar diseÃ±o completo
design_document = f\"\"\"
================================================================================
TAREA 22: DISEÃ‘O COMPLETO DE IMPLEMENTACIÃ“N KNN EN C
================================================================================

{flowchart_text}

{structures_doc}

FUNCIONES PRINCIPALES:
================================================================================

1. load_dataset(filename, n_features, n_classes)
   - Lee archivo CSV lÃ­nea por lÃ­nea con fgets
   - Parsea features y labels con strtok
   - Retorna Dataset* con datos cargados
   - Maneja errores de lectura y memoria

2. euclidean_distance(point1, point2, n_features)
   - Calcula suma de diferencias al cuadrado
   - Aplica sqrt() del resultado (math.h)
   - Complejidad: O(d) donde d=features

3. knn_predict_single(model, test_point)
   - Calcula distancias a todos los puntos
   - Ordena con qsort estÃ¡ndar de C
   - Toma k vecinos mÃ¡s cercanos
   - Realiza votaciÃ³n mayoritaria
   - Complejidad: O(n*d + n*log(n))

4. majority_vote(neighbors, k, n_classes)
   - Inicializa array de contadores con calloc
   - Cuenta votos por clase en un bucle
   - Encuentra clase con mÃ¡s votos
   - Maneja empates (primera clase encontrada)
   - Complejidad: O(k + c)

5. calculate_accuracy(y_true, y_pred, n_samples)
   - Compara predicciones con etiquetas reales
   - Cuenta aciertos
   - Retorna porcentaje de aciertos
   - Complejidad: O(n)

6. print_confusion_matrix(y_true, y_pred, n_samples, n_classes)
   - Crea matriz cÃ—c con malloc
   - Llena matriz contando coincidencias
   - Imprime matriz formateada
   - Libera memoria
   - Complejidad: O(n + cÂ²)

7. print_per_class_metrics(y_true, y_pred, n_samples, n_classes)
   - Calcula TP, FP, FN por clase
   - Calcula Precision, Recall, F1-Score
   - Imprime tabla formateada
   - Complejidad: O(n * c)

OPTIMIZACIONES IMPLEMENTADAS:
================================================================================

1. qsort estÃ¡ndar:
   - Usa implementaciÃ³n optimizada de stdlib
   - MÃ¡s eficiente que sorting manual
   - Bien probada y confiable

2. NormalizaciÃ³n Previa:
   - Datos normalizados en Python antes de exportar
   - Evita operaciones de normalizaciÃ³n en C
   - Reduce complejidad del cÃ³digo C

3. Lectura Eficiente:
   - Buffer de lectura para CSV (MAX_LINE_LENGTH)
   - Parseo optimizado con strtok
   - Una sola pasada por el archivo (despuÃ©s de contar)

4. GestiÃ³n de Memoria:
   - malloc solo cuando es necesario
   - free inmediato despuÃ©s de uso
   - calloc para inicializar arrays en cero

LIMITACIONES ACEPTADAS:
================================================================================

1. Dataset pequeÃ±o (1,000 muestras):
   - Compromiso entre tiempo de ejecuciÃ³n y demostraciÃ³n
   - Para datasets grandes, se requieren estructuras avanzadas (KD-Tree)

2. Features limitadas (10):
   - Reduce complejidad de lectura
   - Mantiene cÃ³digo simple y entendible
   - Suficiente para demostraciÃ³n

3. Sin optimizaciones avanzadas:
   - No usa KD-Tree ni Ball Tree (reducirÃ­an a O(log(n)))
   - No paraleliza cÃ¡lculos (posible con OpenMP)
   - Prioriza claridad sobre velocidad extrema

4. MAX_FEATURES fijo:
   - Define lÃ­mite mÃ¡ximo en compile-time
   - Simplifica gestiÃ³n de memoria
   - Evita malloc dentro de DataPoint

COMPILACIÃ“N Y EJECUCIÃ“N:
================================================================================

gcc -o knn_classifier knn_classifier.c -lm -O2 -Wall -Wextra

Flags:
- -lm: Enlazar librerÃ­a matemÃ¡tica (para sqrt())
- -O2: OptimizaciÃ³n nivel 2 (balance velocidad/tamaÃ±o)
- -Wall -Wextra: Todos los warnings (cÃ³digo limpio)

./knn_classifier train_data_c.csv test_data_c.csv 5

Argumentos:
1. train_data_c.csv - Archivo de entrenamiento
2. test_data_c.csv - Archivo de prueba
3. 5 - Valor de k (vecinos)

ARCHIVOS GENERADOS:
================================================================================

1. knn_classifier.c     - ImplementaciÃ³n completa (595 lÃ­neas)
2. Makefile             - Script de compilaciÃ³n
3. train_data_c.csv     - Datos de entrenamiento (generados desde Python)
4. test_data_c.csv      - Datos de prueba (generados desde Python)
5. resultados_knn_c.txt - Resultados de ejecuciÃ³n

================================================================================
TAREA 22 COMPLETADA âœ…
================================================================================
\"\"\"

with open('tarea22_diseno_completo.txt', 'w', encoding='utf-8') as f:
    f.write(design_document)

print("\\nâœ… DiseÃ±o completo guardado en: tarea22_diseno_completo.txt")

# Crear visualizaciÃ³n de la arquitectura
fig, ax = plt.subplots(figsize=(14, 10))
ax.axis('off')

# TÃ­tulo
ax.text(0.5, 0.95, 'Arquitectura del Sistema KNN en C', 
        ha='center', va='top', fontsize=18, fontweight='bold')

# Capas del sistema
layers = [
    ('Capa de Datos', ['CSV Reader', 'Parser', 'Memory Manager'], 0.80, '#FF6B6B'),
    ('Estructuras', ['DataPoint', 'Dataset', 'Neighbor', 'KNNModel'], 0.60, '#4ECDC4'),
    ('Algoritmo KNN', ['Distance', 'Sort', 'Vote'], 0.40, '#45B7D1'),
    ('EvaluaciÃ³n', ['Accuracy', 'Confusion Matrix', 'Metrics'], 0.20, '#96CEB4')
]

for layer_name, components, y_pos, color in layers:
    # Dibujar caja de capa
    rect = plt.Rectangle((0.05, y_pos-0.08), 0.9, 0.12, 
                         facecolor=color, edgecolor='black', 
                         linewidth=2, alpha=0.3)
    ax.add_patch(rect)
    
    # Nombre de capa
    ax.text(0.5, y_pos+0.02, layer_name, 
            ha='center', va='center', fontsize=14, fontweight='bold')
    
    # Componentes
    n_comp = len(components)
    x_step = 0.8 / n_comp
    for j, comp in enumerate(components):
        x_pos = 0.1 + (j + 0.5) * x_step
        
        # Caja de componente
        comp_rect = plt.Rectangle((x_pos-0.06, y_pos-0.05), 0.12, 0.04,
                                  facecolor='white', edgecolor='black',
                                  linewidth=1.5)
        ax.add_patch(comp_rect)
        
        # Texto de componente
        ax.text(x_pos, y_pos-0.03, comp, 
               ha='center', va='center', fontsize=9)

# Flechas entre capas
for i in range(len(layers)-1):
    y_from = layers[i][2] - 0.08
    y_to = layers[i+1][2] + 0.04
    ax.arrow(0.5, y_from, 0, y_to-y_from+0.01, 
            head_width=0.03, head_length=0.02, fc='black', ec='black', lw=2)

# InformaciÃ³n adicional
info_text = 'CompilaciÃ³n: gcc -o knn knn_classifier.c -lm -O2\\n'
info_text += 'EjecuciÃ³n: ./knn train.csv test.csv 5\\n'
info_text += 'OptimizaciÃ³n: O(n*d + n*log(n)) por predicciÃ³n'
ax.text(0.5, 0.05, info_text, ha='center', va='top', 
       fontsize=10, family='monospace',
       bbox=dict(boxstyle='round', facecolor='lightyellow', edgecolor='black'))

plt.xlim(0, 1)
plt.ylim(0, 1)
plt.tight_layout()
plt.savefig('tarea22_arquitectura_sistema.png', dpi=300, bbox_inches='tight')
plt.show()

print("âœ… Arquitectura guardada en: tarea22_arquitectura_sistema.png")
print("\\n" + "="*80)
print("TAREA 22 COMPLETADA âœ…")
print("="*80)"""

def main():
    """Main function to build complete notebook"""
    print("Building complete Section 6 notebook...")
    
    # Load existing notebook
    notebook = load_notebook()
    print(f"Loaded notebook with {len(notebook['cells'])} cells")
    
    # Add Tarea 22
    add_cell(notebook, "markdown", build_tarea22_markdown())
    add_cell(notebook, "code", build_tarea22_code())
    
    # Save updated notebook
    save_notebook(notebook)
    print(f"âœ… Notebook updated with {len(notebook['cells'])} cells")
    print("âœ… Tarea 22 added successfully!")

if __name__ == "__main__":
    main()
