# AN√ÅLISIS DE COMPATIBILIDAD DE RUTAS EN NOTEBOOKS

**Fecha**: 20 de noviembre, 2025
**Estado**: ‚ùå **LAS RUTAS NO SON COMPATIBLES CON LA NUEVA ESTRUCTURA**

---

## üéØ PROBLEMA IDENTIFICADO

Despu√©s de reorganizar el proyecto en la nueva estructura de carpetas, los notebooks **NO** han sido actualizados para usar las rutas correctas. Todos los notebooks siguen usando rutas relativas que asumen que los archivos est√°n en el mismo directorio que el notebook.

### Nueva Estructura de Carpetas
```
Ia_EDA_analysis/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Dataset original
‚îÇ   ‚îî‚îÄ‚îÄ processed/              # Datos procesados, modelos PKL
‚îú‚îÄ‚îÄ notebooks/                  # NOTEBOOKS EST√ÅN AQU√ç
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îú‚îÄ‚îÄ seccion1/              # Outputs de secci√≥n 1
‚îÇ   ‚îú‚îÄ‚îÄ seccion2/              # Outputs de secci√≥n 2
‚îÇ   ‚îú‚îÄ‚îÄ seccion3/              # Outputs de secci√≥n 3
‚îÇ   ‚îú‚îÄ‚îÄ seccion4/              # Outputs de secci√≥n 4
‚îÇ   ‚îú‚îÄ‚îÄ seccion5/              # Outputs de secci√≥n 5
‚îÇ   ‚îî‚îÄ‚îÄ seccion6/              # Outputs de secci√≥n 6
‚îî‚îÄ‚îÄ src/
```

### Navegaci√≥n desde notebooks/
Desde la carpeta `notebooks/`, las rutas correctas deben ser:
- Dataset: `../data/raw/dataset_saber11_reducido_estratificado.csv`
- Datos procesados: `../data/processed/X_train.csv`
- Outputs: `../outputs/seccion{X}/archivo.png`

---

## üìã AN√ÅLISIS POR NOTEBOOK

### ‚ùå seccion1.ipynb

**PROBLEMAS ENCONTRADOS:**

| L√≠nea (aprox) | C√≥digo Actual | C√≥digo Correcto |
|---------------|---------------|-----------------|
| ~105 | `pd.read_csv('dataset_saber11_reducido_estratificado.csv')` | `pd.read_csv('../data/raw/dataset_saber11_reducido_estratificado.csv')` |
| ~1436 | `open('checkpoint_seccion1_tareas1-3.json', 'w')` | `open('../outputs/seccion1/checkpoint_seccion1_tareas1-3.json', 'w')` |
| ~3165 | `open('checkpoint_seccion1_completa.json', 'w')` | `open('../outputs/seccion1/checkpoint_seccion1_completa.json', 'w')` |
| M√∫ltiples | `plt.savefig('*.png')` | `plt.savefig('../outputs/seccion1/*.png')` |
| M√∫ltiples | `open('variables_*.txt', 'w')` | `open('../outputs/seccion1/variables_*.txt', 'w')` |

**ARCHIVOS AFECTADOS:**
- Dataset: `dataset_saber11_reducido_estratificado.csv`
- Checkpoints: `checkpoint_seccion1_tareas1-3.json`, `checkpoint_seccion1_completa.json`
- Outputs: `variables_seleccionadas.txt`, `variables_influyentes_top20.txt`
- Visualizaciones: ~15 archivos PNG

---

### ‚ùå seccion2.ipynb

**PROBLEMAS ENCONTRADOS:**

| L√≠nea (aprox) | C√≥digo Actual | C√≥digo Correcto |
|---------------|---------------|-----------------|
| ~90 | `pd.read_csv('dataset_saber11_reducido_estratificado.csv')` | `pd.read_csv('../data/raw/dataset_saber11_reducido_estratificado.csv')` |
| ~98 | `open('checkpoint_seccion1_completa.json', 'r')` | `open('../outputs/seccion1/checkpoint_seccion1_completa.json', 'r')` |
| M√∫ltiples | `to_csv('X_train.csv')` | `to_csv('../data/processed/X_train.csv')` |
| M√∫ltiples | `to_csv('y_train.csv')` | `to_csv('../data/processed/y_train.csv')` |
| M√∫ltiples | `open('preprocessing_objects.pkl', 'wb')` | `open('../data/processed/preprocessing_objects.pkl', 'wb')` |
| M√∫ltiples | `open('pca_models.pkl', 'wb')` | `open('../data/processed/pca_models.pkl', 'wb')` |
| M√∫ltiples | `plt.savefig('*.png')` | `plt.savefig('../outputs/seccion2/*.png')` |

**ARCHIVOS AFECTADOS:**
- **Lectura:**
  - Dataset: `dataset_saber11_reducido_estratificado.csv` ‚Üí `../data/raw/`
  - Checkpoint: `checkpoint_seccion1_completa.json` ‚Üí `../outputs/seccion1/`

- **Escritura (data/processed/):**
  - `X_train.csv`, `X_test.csv`
  - `y_train.csv`, `y_test.csv`
  - `X_train_pca.csv`, `X_test_pca.csv`
  - `preprocessing_objects.pkl`
  - `train_test_split.pkl`
  - `pca_models.pkl`

- **Escritura (outputs/seccion2/):**
  - ~3 visualizaciones PNG (PCA)

---

### ‚ùå seccion3.ipynb

**PROBLEMAS ENCONTRADOS (estimados):**

| Operaci√≥n | C√≥digo Actual | C√≥digo Correcto |
|-----------|---------------|-----------------|
| Leer datos | `open('train_test_split.pkl', 'rb')` | `open('../data/processed/train_test_split.pkl', 'rb')` |
| Guardar outputs | `plt.savefig('*.png')` | `plt.savefig('../outputs/seccion3/*.png')` |
| Guardar texto | `open('resumen_seccion3.txt', 'w')` | `open('../outputs/seccion3/resumen_seccion3.txt', 'w')` |

**ARCHIVOS AFECTADOS:**
- **Lectura:** `train_test_split.pkl`, `preprocessing_objects.pkl` ‚Üí `../data/processed/`
- **Escritura:** `resumen_seccion3.txt`, ~8 PNG ‚Üí `../outputs/seccion3/`

---

### ‚ùå seccion4.ipynb

**PROBLEMAS ENCONTRADOS:**

| L√≠nea (aprox) | C√≥digo Actual | C√≥digo Correcto |
|---------------|---------------|-----------------|
| ~131 | `open('train_test_split.pkl', 'rb')` | `open('../data/processed/train_test_split.pkl', 'rb')` |
| ~147 | `open('preprocessing_objects.pkl', 'rb')` | `open('../data/processed/preprocessing_objects.pkl', 'rb')` |
| ~159 | `open('pca_models.pkl', 'rb')` | `open('../data/processed/pca_models.pkl', 'rb')` |
| ~479 | `plt.savefig('model_comparison_metrics.png')` | `plt.savefig('../outputs/seccion4/model_comparison_metrics.png')` |
| ~697 | `plt.savefig('cross_validation_analysis.png')` | `plt.savefig('../outputs/seccion4/cross_validation_analysis.png')` |
| ~1024 | `plt.savefig('hyperparameter_tuning_comparison.png')` | `plt.savefig('../outputs/seccion4/hyperparameter_tuning_comparison.png')` |
| ~1028 | `open('tuned_models.pkl', 'wb')` | `open('../data/processed/tuned_models.pkl', 'wb')` |
| M√∫ltiples | `plt.savefig('*.png')` | `plt.savefig('../outputs/seccion4/*.png')` |

**ARCHIVOS AFECTADOS:**
- **Lectura (data/processed/):**
  - `train_test_split.pkl`
  - `preprocessing_objects.pkl`
  - `pca_models.pkl`

- **Escritura (data/processed/):**
  - `tuned_models.pkl`
  - `feature_importance_analysis.pkl`
  - `seccion4_complete_results.pkl`

- **Escritura (outputs/seccion4/):**
  - `model_comparison_metrics.png`
  - `confusion_matrices.png`
  - `roc_curves_multiclass.png`
  - `cross_validation_analysis.png`
  - `hyperparameter_tuning_comparison.png`
  - `feature_importance_random_forest.png`
  - `feature_coefficients_logistic.png`
  - `decision_tree_structure.png`
  - `feature_importance_comparison.png`
  - `resumen_seccion4.txt`
  - `README_SECCION4.md`

---

### ‚ùå seccion5.ipynb

**PROBLEMAS ENCONTRADOS (parcialmente mitigados con l√≥gica condicional):**

| L√≠nea (aprox) | C√≥digo Actual | C√≥digo Correcto |
|---------------|---------------|-----------------|
| ~173-178 | L√≥gica condicional con rutas incorrectas | `pd.read_csv('../data/raw/dataset_saber11_reducido_estratificado.csv')` |
| M√∫ltiples | `open('train_test_split.pkl', 'rb')` | `open('../data/processed/train_test_split.pkl', 'rb')` |
| M√∫ltiples | `open('seccion4_complete_results.pkl', 'rb')` | `open('../data/processed/seccion4_complete_results.pkl', 'rb')` |
| M√∫ltiples | `plt.savefig('*.png')` | `plt.savefig('../outputs/seccion5/*.png')` |

**NOTA:** Este notebook tiene l√≥gica condicional que intenta buscar archivos en m√∫ltiples ubicaciones, pero las rutas siguen siendo incorrectas.

**ARCHIVOS AFECTADOS:**
- **Lectura (data/processed/):**
  - `train_test_split.pkl`
  - `preprocessing_objects.pkl`
  - `seccion4_complete_results.pkl`

- **Escritura (data/processed/):**
  - `modelo_mejorado.pkl`

- **Escritura (outputs/seccion5/):**
  - ~8 visualizaciones PNG
  - `seccion5_reporte_final.txt`
  - `README_SECCION5.md`

---

### ‚ùå seccion6.ipynb

**PROBLEMAS ENCONTRADOS:**

| L√≠nea (aprox) | C√≥digo Actual | C√≥digo Correcto |
|---------------|---------------|-----------------|
| ~1455 | Menci√≥n de `../datasets/` (ruta obsoleta) | `../data/raw/` |
| ~1546-1549 | `pd.read_csv('X_train.csv')` | `pd.read_csv('../data/processed/X_train.csv')` |
| ~1719 | `open('train_test_split.pkl', 'rb')` | `open('../data/processed/train_test_split.pkl', 'rb')` |
| ~333 | `plt.savefig('tarea21_algorithm_selection.png')` | `plt.savefig('../outputs/seccion6/tarea21_algorithm_selection.png')` |
| ~387 | `open('tarea21_justificacion_algoritmo.txt', 'w')` | `open('../outputs/seccion6/tarea21_justificacion_algoritmo.txt', 'w')` |
| M√∫ltiples | `plt.savefig('*.png')` | `plt.savefig('../outputs/seccion6/*.png')` |
| M√∫ltiples | `open('tarea*.txt', 'w')` | `open('../outputs/seccion6/tarea*.txt', 'w')` |

**ARCHIVOS GENERADOS PARA C (nueva celda):**
```python
# Esta celda genera CSVs para C - las rutas est√°n MAL
train_c.to_csv('seccion6_c_docker/data/train_data_c.csv', index=False)
test_c.to_csv('seccion6_c_docker/data/test_data_c.csv', index=False)

# Deber√≠a ser:
train_c.to_csv('../data/processed/train_data_c.csv', index=False)
test_c.to_csv('../data/processed/test_data_c.csv', index=False)
```

**ARCHIVOS AFECTADOS:**
- **Lectura (data/processed/):**
  - `train_test_split.pkl`
  - `X_train.csv`, `X_test.csv`
  - `y_train.csv`, `y_test.csv`

- **Escritura (data/processed/):**
  - `train_data_c.csv`
  - `test_data_c.csv`

- **Escritura (outputs/seccion6/):**
  - `tarea21_algorithm_selection.png`
  - `tarea21_justificacion_algoritmo.txt`
  - `tarea22_diseno_completo.txt`
  - `tarea22_arquitectura_sistema.png`
  - `tarea24_comparison_python_vs_c.png`
  - `tarea24_comparacion_completa.txt`
  - `tarea25_analisis_limitaciones.txt`
  - `tarea25_optimizaciones_comparacion.png`

---

## üìä RESUMEN DE IMPACTO

### Total de Rutas Incorrectas

| Notebook | Rutas Lectura | Rutas Escritura | Total |
|----------|--------------|----------------|-------|
| seccion1.ipynb | 1 | ~20 | ~21 |
| seccion2.ipynb | 2 | ~12 | ~14 |
| seccion3.ipynb | 2 | ~10 | ~12 |
| seccion4.ipynb | 3 | ~15 | ~18 |
| seccion5.ipynb | 3 | ~12 | ~15 |
| seccion6.ipynb | 4 | ~10 | ~14 |
| **TOTAL** | **15** | **~79** | **~94** |

### Archivos por Destino

**data/raw/** (lectura):
- `dataset_saber11_reducido_estratificado.csv`

**data/processed/** (lectura):
- `checkpoint_seccion1_completa.json` (actualmente en outputs/seccion1/)
- `train_test_split.pkl`
- `preprocessing_objects.pkl`
- `pca_models.pkl`
- `X_train.csv`, `X_test.csv`
- `y_train.csv`, `y_test.csv`
- `seccion4_complete_results.pkl`
- `tuned_models.pkl`

**data/processed/** (escritura):
- Todos los CSVs (train/test)
- Todos los PKL (modelos, preprocesamiento, PCA)
- CSVs para C (train_data_c.csv, test_data_c.csv)

**outputs/seccion{1-6}/** (escritura):
- Todas las visualizaciones PNG
- Todos los archivos de texto (.txt)
- Todos los READMEs
- Todos los checkpoints JSON (seccion1)

---

## üîß SOLUCI√ìN PROPUESTA

### Opci√≥n 1: Actualizaci√≥n Manual (Recomendado)
Actualizar cada notebook l√≠nea por l√≠nea para usar las rutas correctas. Esto garantiza control total y evita errores.

**Ventajas:**
- Control total sobre cada cambio
- Verificaci√≥n visual de cada ruta
- Evita errores de reemplazo masivo

**Desventajas:**
- Requiere tiempo (~2-3 horas)
- Propenso a errores humanos

### Opci√≥n 2: Script de Reemplazo Autom√°tico
Crear un script que actualice todas las rutas autom√°ticamente usando expresiones regulares.

**Ventajas:**
- R√°pido (< 5 minutos)
- Consistente

**Desventajas:**
- Riesgo de romper c√≥digo si hay casos especiales
- Requiere testing exhaustivo

### Opci√≥n 3: Funci√≥n Helper
Agregar una celda al inicio de cada notebook con funciones helper que manejen las rutas:

```python
# Celda 1 de cada notebook
import os

# Configuraci√≥n de rutas
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_RAW = os.path.join(BASE_DIR, 'data', 'raw')
DATA_PROCESSED = os.path.join(BASE_DIR, 'data', 'processed')
OUTPUTS = os.path.join(BASE_DIR, 'outputs', 'seccionX')  # X seg√∫n notebook

# Funciones helper
def load_dataset():
    return pd.read_csv(os.path.join(DATA_RAW, 'dataset_saber11_reducido_estratificado.csv'))

def load_processed(filename):
    return pd.read_csv(os.path.join(DATA_PROCESSED, filename))

def save_output(filename, **kwargs):
    filepath = os.path.join(OUTPUTS, filename)
    if filename.endswith('.png'):
        plt.savefig(filepath, **kwargs)
    elif filename.endswith('.txt'):
        return open(filepath, 'w', **kwargs)
    # etc...
```

**Ventajas:**
- Rutas centralizadas
- F√°cil de mantener
- Portable entre entornos

**Desventajas:**
- Requiere refactorizar todo el c√≥digo
- Cambios extensos en cada notebook

---

## üéØ RECOMENDACI√ìN

**Opci√≥n 1 (Actualizaci√≥n Manual)** es la m√°s recomendada por:

1. **Seguridad**: No hay riesgo de romper c√≥digo existente
2. **Claridad**: Cada ruta se actualiza expl√≠citamente
3. **Verificaci√≥n**: Se puede verificar visualmente cada cambio
4. **Aprendizaje**: Permite revisar el c√≥digo mientras se actualiza

### Plan de Implementaci√≥n

**Orden de actualizaci√≥n (para minimizar errores):**
1. ‚úÖ seccion1.ipynb - Genera datos base
2. ‚úÖ seccion2.ipynb - Usa datos de secci√≥n 1, genera train/test
3. ‚úÖ seccion3.ipynb - Usa datos de secci√≥n 2
4. ‚úÖ seccion4.ipynb - Usa datos de secci√≥n 2
5. ‚úÖ seccion5.ipynb - Usa datos de secciones 2 y 4
6. ‚úÖ seccion6.ipynb - Usa datos de secci√≥n 2

**Tiempo estimado**: 2-3 horas
**Complejidad**: Media
**Riesgo**: Bajo (si se hace cuidadosamente)

---

## üìù PASOS SIGUIENTES

1. **Decidir enfoque**: Manual, Script, o Helper Functions
2. **Crear backup**: Copiar notebooks antes de modificar
3. **Actualizar notebooks**: Uno por uno, en orden de dependencia
4. **Verificar**: Revisar que todas las rutas sean correctas
5. **Probar**: Ejecutar cada notebook para verificar funcionamiento
6. **Commit**: Guardar cambios en Git con mensaje descriptivo

---

## ‚ö†Ô∏è NOTAS IMPORTANTES

### Carpeta `seccion6_c_docker/data/`

La nueva celda en seccion6.ipynb genera CSVs en:
```
seccion6_c_docker/data/train_data_c.csv
seccion6_c_docker/data/test_data_c.csv
```

Pero esta carpeta YA NO EXISTE en la nueva estructura. El c√≥digo C est√° en:
```
src/c_implementation/
```

**Soluci√≥n:**
1. Generar CSVs en `data/processed/train_data_c.csv`
2. Actualizar `src/c_implementation/` para leer desde la ruta correcta:
   ```bash
   # En Docker o scripts, usar:
   ../data/processed/train_data_c.csv
   ../data/processed/test_data_c.csv
   ```

3. O usar vol√∫menes Docker para montar `data/processed/` dentro del contenedor

### Ejecuci√≥n Relativa vs Absoluta

Todos los notebooks asumen ejecuci√≥n desde la carpeta `notebooks/`. Si se ejecutan desde otra ubicaci√≥n, las rutas relativas `../` fallar√°n.

**Soluci√≥n:**
- Siempre ejecutar notebooks desde Jupyter Lab/VSCode con working directory = `notebooks/`
- O usar `os.path` para rutas absolutas basadas en la ubicaci√≥n del notebook

---

**Fecha de an√°lisis**: 20 de noviembre, 2025
**Estado**: Pendiente de correcci√≥n
**Prioridad**: üî¥ **ALTA** - Los notebooks no funcionar√°n en la nueva estructura
