# Secci√≥n 4: Aprendizaje Supervisado

## üìã Descripci√≥n General

Esta secci√≥n implementa **5 tareas evaluables** (Tareas 13-17) del proyecto final de Inteligencia Artificial, enfocadas en el entrenamiento, evaluaci√≥n y optimizaci√≥n de modelos de clasificaci√≥n supervisada.

## üéØ Objetivo

Predecir el nivel de desempe√±o en ingl√©s (`DESEMP_INGLES`) de estudiantes utilizando m√∫ltiples algoritmos de machine learning, comparando su rendimiento y optimizando sus hiperpar√°metros.

## üìä Estructura del Notebook

El notebook `seccion4.ipynb` contiene **9 celdas** organizadas de la siguiente manera:

### 1. Header (Markdown)
- Informaci√≥n del proyecto y objetivos

### 2. Configuraci√≥n Inicial
- Importaci√≥n de bibliotecas
- Configuraci√≥n de random_state y estilos
- Definici√≥n de constantes

### 3. Carga de Datos
- Carga de train/test split de Secci√≥n 2
- Carga de objetos de preprocesamiento
- Verificaci√≥n de distribuci√≥n de clases

### 4. TAREA 13: Entrenamiento de Modelos
Implementa **5 modelos de clasificaci√≥n**:
- ‚úÖ Decision Tree Classifier
- ‚úÖ Random Forest Classifier (100 √°rboles)
- ‚úÖ Logistic Regression (multinomial)
- ‚úÖ Support Vector Machine (RBF kernel)
- ‚úÖ K-Nearest Neighbors (k=7)

**Salidas**:
- Modelos entrenados
- Predicciones en conjunto de test
- Tiempos de entrenamiento

### 5. TAREA 14: Comparaci√≥n de Modelos
Eval√∫a todos los modelos con m√∫ltiples m√©tricas:
- Accuracy, Precision, Recall, F1-Score
- Matrices de confusi√≥n (normalizadas)
- Classification reports detallados
- Visualizaciones comparativas

**Archivos generados**:
- `model_comparison_metrics.png`
- `confusion_matrices.png`

### 6. TAREA 15: Validaci√≥n Cruzada
An√°lisis de estabilidad con 5-Fold Stratified CV:
- Distribuci√≥n de scores por fold
- An√°lisis de overfitting (Train-Test Gap)
- M√©tricas de estabilidad (desviaci√≥n est√°ndar)
- Comparaci√≥n de varianza

**Archivos generados**:
- `cross_validation_analysis.png`

### 7. TAREA 16: Ajuste de Hiperpar√°metros
Optimizaci√≥n de los mejores modelos:
- **Grid Search** para Random Forest y Logistic Regression
- **Random Search** para Decision Tree
- Comparaci√≥n Before/After
- Guardado de modelos optimizados

**Archivos generados**:
- `hyperparameter_tuning_comparison.png`
- `tuned_models.pkl`

### 8. TAREA 17: Feature Importance
An√°lisis de importancia de variables:
- **Random Forest**: Importancia basada en reducci√≥n de impureza
- **Logistic Regression**: An√°lisis de coeficientes por clase
- **Decision Tree**: Visualizaci√≥n de estructura del √°rbol
- **Consenso**: Ranking agregado de features

**Archivos generados**:
- `feature_importance_random_forest.png`
- `feature_coefficients_logistic.png`
- `decision_tree_structure.png`
- `feature_importance_comparison.png`
- `feature_importance_analysis.pkl`

### 9. Resumen Final
- Tabla resumen de todas las tareas
- Conclusiones y hallazgos clave
- Recomendaciones para Secci√≥n 5
- Guardado de resultados completos

**Archivos generados**:
- `seccion4_complete_results.pkl`
- `resumen_seccion4.txt`

## üîß Requisitos Previos

### Archivos Necesarios
El notebook requiere que **Secci√≥n 2** haya sido ejecutada previamente para generar:
- `train_test_split.pkl` - Divisi√≥n train/test estratificada
- `preprocessing_objects.pkl` - Encoders, scalers, mapeos
- `pca_models.pkl` - Modelos PCA (opcional)

### Bibliotecas Python
```python
pandas
numpy
matplotlib
seaborn
scikit-learn
scipy
pickle
json
```

## ‚ñ∂Ô∏è C√≥mo Ejecutar

### Opci√≥n 1: Jupyter Notebook
```bash
cd notebooks/
jupyter notebook seccion4.ipynb
```
Ejecutar todas las celdas en orden: `Cell ‚Üí Run All`

### Opci√≥n 2: JupyterLab
```bash
cd notebooks/
jupyter lab seccion4.ipynb
```

### Opci√≥n 3: VS Code
Abrir `seccion4.ipynb` con la extensi√≥n de Jupyter en VS Code

## üìà Resultados Esperados

### M√©tricas T√≠picas
- **Accuracy**: 0.45 - 0.55 (problema multiclase desafiante)
- **F1-Score**: 0.44 - 0.54
- **Tiempo de entrenamiento**: 5-120 segundos seg√∫n modelo

### Modelos con Mejor Rendimiento
T√≠picamente:
1. **Random Forest**: Balance entre precisi√≥n y estabilidad
2. **Logistic Regression**: R√°pido y interpretable
3. **Decision Tree**: Interpretable pero propenso a overfitting

### Insights Comunes
- Clases extremas (A-, B+) son m√°s distinguibles
- Traslape significativo entre clases intermedias (A1, A2, B1)
- 10-15 features explican 90% de la importancia
- Puntuaciones de pruebas SABER 11 son las features m√°s importantes

## üìÅ Archivos Generados

| Archivo | Descripci√≥n | Tama√±o Aprox. |
|---------|-------------|---------------|
| `model_comparison_metrics.png` | Gr√°ficos comparativos de m√©tricas | ~500KB |
| `confusion_matrices.png` | Matrices de confusi√≥n de todos los modelos | ~800KB |
| `cross_validation_analysis.png` | An√°lisis de CV y estabilidad | ~600KB |
| `hyperparameter_tuning_comparison.png` | Comparaci√≥n antes/despu√©s tuning | ~400KB |
| `feature_importance_*.png` | Visualizaciones de importancia | ~500KB c/u |
| `tuned_models.pkl` | Modelos optimizados | ~50MB |
| `feature_importance_analysis.pkl` | Resultados de an√°lisis | ~500KB |
| `seccion4_complete_results.pkl` | Todos los resultados | ~100MB |
| `resumen_seccion4.txt` | Resumen textual | ~5KB |

## ‚ö†Ô∏è Consideraciones Importantes

### Rendimiento
- **SVM**: Usa muestra de 20,000 observaciones por eficiencia
- **Grid Search**: Puede tardar 10-30 minutos seg√∫n configuraci√≥n
- **Random Forest**: Usa n_jobs=-1 para paralelizaci√≥n

### Memoria
- Dataset completo: ~217K filas requiere ~2GB RAM
- Modelos entrenados: ~500MB adicionales
- Se recomienda m√≠nimo 4GB RAM disponible

### Reproducibilidad
- Todos los modelos usan `random_state=42`
- Resultados deber√≠an ser id√©nticos en m√∫ltiples ejecuciones
- Peque√±as variaciones pueden ocurrir por paralelizaci√≥n

## üêõ Troubleshooting

### Error: "FileNotFoundError: train_test_split.pkl"
**Soluci√≥n**: Ejecutar primero `seccion2.ipynb` para generar archivos de preprocesamiento

### Error: "MemoryError"
**Soluci√≥n**: 
- Reducir tama√±o de muestra para SVM
- Disminuir n_estimators de Random Forest
- Ejecutar en entorno con m√°s RAM

### Error: "ConvergenceWarning" en Logistic Regression
**Soluci√≥n**: Aumentar `max_iter` a 2000 o m√°s

### Ejecuci√≥n muy lenta
**Soluci√≥n**:
- Reducir iteraciones de Grid/Random Search
- Usar muestras m√°s peque√±as
- Verificar que n_jobs=-1 est√© funcionando

## üìö Referencias

### Algoritmos Implementados
- Scikit-learn Documentation: https://scikit-learn.org/
- Decision Trees: https://scikit-learn.org/stable/modules/tree.html
- Random Forests: https://scikit-learn.org/stable/modules/ensemble.html
- SVM: https://scikit-learn.org/stable/modules/svm.html

### M√©tricas y Evaluaci√≥n
- Classification Metrics: https://scikit-learn.org/stable/modules/model_evaluation.html
- Cross-Validation: https://scikit-learn.org/stable/modules/cross_validation.html

## üë• Autor

**Proyecto Final - Inteligencia Artificial ELP 8012**  
Universidad del Norte - Ingenier√≠a de Sistemas  
Profesor: Eduardo Zurek, Ph.D.

## üìù Notas de Versi√≥n

**Versi√≥n 1.0** (Noviembre 2024)
- ‚úÖ Implementaci√≥n completa de 5 tareas (13-17)
- ‚úÖ 5 modelos de clasificaci√≥n
- ‚úÖ Validaci√≥n cruzada estratificada
- ‚úÖ Optimizaci√≥n de hiperpar√°metros
- ‚úÖ An√°lisis exhaustivo de feature importance
- ‚úÖ Visualizaciones publication-ready
- ‚úÖ C√≥digo modular y bien documentado

---

## üöÄ Pr√≥ximos Pasos

Despu√©s de completar esta secci√≥n, continuar con:
- **Secci√≥n 5**: Evaluaci√≥n e Interpretaci√≥n
  - Comparaci√≥n supervisado vs no supervisado
  - T√©cnicas de mejora (SMOTE, Ensemble, Feature Engineering)
  - Discusi√≥n cr√≠tica y aplicabilidad real

- **Secci√≥n 6**: Implementaci√≥n en C
  - Selecci√≥n de algoritmo para implementar
  - Dise√±o de estructuras de datos
  - C√≥digo C con entrenamiento y predicci√≥n
  - Comparaci√≥n con versi√≥n Python
