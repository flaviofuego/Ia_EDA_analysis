
================================================================================
REPORTE FINAL - SECCIÃ“N 5: EVALUACIÃ“N E INTERPRETACIÃ“N
Proyecto Final - Inteligencia Artificial (ELP 8012)
Universidad del Norte
================================================================================


PROYECTO: AnÃ¡lisis y PredicciÃ³n de DesempeÃ±o en InglÃ©s - Pruebas Saber 11

DATASET:
- Fuente: ICFES - Pruebas Saber 11 (Colombia)
- TamaÃ±o: 217,581 observaciones
- Features: 50 variables predictoras
- Variable Objetivo: DESEMP_INGLES (5 clases)
- Clases: A-, A1, A2, B+, B1

METODOLOGÃA APLICADA:
âœ“ SecciÃ³n 1: ComprensiÃ³n de datos y EDA
âœ“ SecciÃ³n 2: Preprocesamiento y transformaciÃ³n
âœ“ SecciÃ³n 3: Aprendizaje no supervisado (clustering)
âœ“ SecciÃ³n 4: Aprendizaje supervisado (clasificaciÃ³n)
âœ“ SecciÃ³n 5: EvaluaciÃ³n, mejoras e interpretaciÃ³n

TÃ‰CNICAS IMPLEMENTADAS:
- Clustering: K-Means, JerÃ¡rquico, DBSCAN
- ClasificaciÃ³n: Random Forest, Logistic Regression, SVM, KNN, Gradient Boosting
- Mejoras: SMOTE, Feature Engineering, Ensemble Methods (Voting, Stacking)
- MÃ©tricas: Accuracy, Balanced Accuracy, F1-Score, Cohen's Kappa, ARI, NMI



2.1. APRENDIZAJE NO SUPERVISADO (Tarea 18):
---------------------------------------------
â€¢ Los clusters naturales muestran concordancia PARCIAL con las clases supervisadas
â€¢ MÃ©trica ARI indica que la estructura de clusters no coincide perfectamente con clases
â€¢ InterpretaciÃ³n: Las clases de desempeÃ±o en inglÃ©s tienen fronteras complejas que
  no son fÃ¡cilmente detectables solo por patrones naturales en los datos
â€¢ ImplicaciÃ³n: Se requiere supervisiÃ³n para identificar correctamente las clases

2.2. APRENDIZAJE SUPERVISADO (Tarea 19):
-----------------------------------------
â€¢ Modelo Baseline (Random Forest): EstableciÃ³ lÃ­nea base de rendimiento
â€¢ SMOTE: MejorÃ³ significativamente el balanced accuracy y recall de clases minoritarias
â€¢ Feature Engineering: Interacciones polinomiales aportaron capacidad predictiva adicional
â€¢ Ensemble Methods: Voting y Stacking alcanzaron el mejor rendimiento global
â€¢ Mejor Modelo: MostrÃ³ mejoras sustanciales en todas las mÃ©tricas

HALLAZGOS CLAVE:
1. El desbalanceo de clases es un desafÃ­o MAYOR en este problema
2. Las tÃ©cnicas de balanceo (SMOTE) son ESENCIALES para resultados equitativos
3. Los ensemble methods superan consistentemente a modelos individuales
4. Feature engineering con interacciones captura relaciones no lineales
5. Balanced Accuracy y Cohen's Kappa son mÃ©tricas mÃ¡s informativas que accuracy simple



3.1. CARACTERÃSTICAS DEL DATASET:
----------------------------------
â€¢ Complejidad: Dataset multidimensional con variables socioeconÃ³micas, acadÃ©micas y demogrÃ¡ficas
â€¢ Desbalanceo: Fuerte desbalanceo de clases (algunas clases son hasta 10x mÃ¡s frecuentes)
â€¢ Correlaciones: Variables acadÃ©micas muestran correlaciÃ³n moderada con desempeÃ±o en inglÃ©s
â€¢ Outliers: Presencia de casos atÃ­picos que representan situaciones excepcionales

3.2. PATRONES IDENTIFICADOS:
-----------------------------
â€¢ DesempeÃ±o en otras materias (matemÃ¡ticas, lectura crÃ­tica) correlaciona con inglÃ©s
â€¢ Factores socioeconÃ³micos influyen significativamente
â€¢ CaracterÃ­sticas del colegio (jornada, naturaleza, ubicaciÃ³n) son predictivas
â€¢ Nivel educativo de los padres muestra asociaciÃ³n con resultados

3.3. DESAFÃOS DEL DATASET:
---------------------------
âœ— Desbalanceo extremo requiere tÃ©cnicas especializadas
âœ— Missing values en algunas variables socioeconÃ³micas
âœ— CategorÃ­as con baja frecuencia en variables categÃ³ricas
âœ— Fronteras de clase no lineales y complejas
âœ— Alta dimensionalidad inicial (muchas features disponibles)



4.1. FORTALEZAS DE CADA ENFOQUE:
---------------------------------

Random Forest:
  âœ“ Robusto a outliers
  âœ“ Maneja bien no linealidades
  âœ“ Proporciona feature importance interpretable
  âœ— Puede overfittear sin regularizaciÃ³n

Logistic Regression:
  âœ“ RÃ¡pido y eficiente
  âœ“ Interpretable (coeficientes)
  âœ“ Funciona bien con datos normalizados
  âœ— Asume relaciones lineales (limitante)

Gradient Boosting:
  âœ“ Excelente rendimiento predictivo
  âœ“ Captura interacciones complejas
  âœ“ Menos propenso a overfitting que RF
  âœ— MÃ¡s lento de entrenar

Ensemble Methods (Voting/Stacking):
  âœ“âœ“ MEJOR rendimiento general
  âœ“âœ“ Combina fortalezas de mÃºltiples modelos
  âœ“âœ“ Reduce varianza y bias simultÃ¡neamente
  âœ— Mayor complejidad computacional
  âœ— Menos interpretable

4.2. LECCIONES SOBRE HIPERPARÃMETROS:
--------------------------------------
â€¢ Grid Search: Exhaustivo pero costoso â†’ Usar para espacios pequeÃ±os
â€¢ Random Search: Eficiente para espacios grandes
â€¢ Cross-Validation: ESENCIAL para evitar overfitting
â€¢ SMOTE antes de split: INCORRECTO (causa data leakage)
â€¢ SMOTE despuÃ©s de split: CORRECTO (solo en train)

4.3. IMPORTANCIA DE LAS MÃ‰TRICAS:
----------------------------------
â€¢ Accuracy: EngaÃ±osa con clases desbalanceadas
â€¢ Balanced Accuracy: MEJOR indicador de rendimiento real
â€¢ F1-Score (weighted): Balancea precision y recall
â€¢ Cohen's Kappa: Considera el acuerdo por azar
â€¢ Confusion Matrix: VisualizaciÃ³n esencial de errores por clase



5.1. LIMITACIONES DEL DATASET:
-------------------------------
âš  Desbalanceo extremo: Dificulta aprendizaje de clases minoritarias
âš  Datos estÃ¡ticos: No capturan evoluciÃ³n temporal del estudiante
âš  Variables proxy: Nivel socioeconÃ³mico es aproximaciÃ³n, no medida directa
âš  Sesgo geogrÃ¡fico: Resultados pueden variar por regiÃ³n
âš  InformaciÃ³n incompleta: Faltan variables como horas de estudio, prÃ¡ctica de inglÃ©s

5.2. LIMITACIONES DE LOS MODELOS:
----------------------------------
âš  GeneralizaciÃ³n: Modelos entrenados en datos histÃ³ricos pueden no generalizar a futuro
âš  Interpretabilidad vs Performance: Ensemble methods son menos interpretables
âš  Costo computacional: Modelos complejos requieren recursos significativos
âš  Mantenimiento: Modelos necesitan reentrenamiento periÃ³dico
âš  Fairness: Riesgo de perpetuar sesgos presentes en datos histÃ³ricos

5.3. LIMITACIONES METODOLÃ“GICAS:
---------------------------------
âš  Trade-offs: Balance entre complejidad, rendimiento e interpretabilidad
âš  ValidaciÃ³n: Cross-validation es costosa en datasets grandes
âš  Escalabilidad: Algunos mÃ©todos no escalan bien (ej: SVM, KNN)
âš  OptimizaciÃ³n: BÃºsqueda de hiperparÃ¡metros no garantiza Ã³ptimo global
âš  EvaluaciÃ³n: MÃ©tricas estÃ¡ndar pueden no capturar todos los aspectos relevantes



6.1. CASOS DE USO PRÃCTICOS:
-----------------------------

ğŸ“Š PARA INSTITUCIONES EDUCATIVAS:
   â€¢ IdentificaciÃ³n temprana de estudiantes en riesgo
   â€¢ DiseÃ±o de intervenciones pedagÃ³gicas personalizadas
   â€¢ AsignaciÃ³n de recursos de refuerzo en inglÃ©s
   â€¢ EvaluaciÃ³n de efectividad de programas de enseÃ±anza

ğŸ“Š PARA FORMULADORES DE POLÃTICA PÃšBLICA:
   â€¢ IdentificaciÃ³n de brechas educativas por regiÃ³n/estrato
   â€¢ DiseÃ±o de polÃ­ticas de mejoramiento de educaciÃ³n en inglÃ©s
   â€¢ AsignaciÃ³n eficiente de presupuesto educativo
   â€¢ Monitoreo de impacto de intervenciones

ğŸ“Š PARA ESTUDIANTES Y FAMILIAS:
   â€¢ PredicciÃ³n de desempeÃ±o y ajuste de expectativas
   â€¢ IdentificaciÃ³n de Ã¡reas de mejora
   â€¢ Toma de decisiones sobre refuerzo acadÃ©mico
   â€¢ PreparaciÃ³n estratÃ©gica para la prueba

6.2. CONSIDERACIONES Ã‰TICAS:
-----------------------------
âš  PRIVACIDAD: Proteger datos sensibles de estudiantes
âš  EQUIDAD: Evitar discriminaciÃ³n por variables socioeconÃ³micas
âš  TRANSPARENCIA: Explicar decisiones basadas en predicciones
âš  ACCOUNTABILITY: Responsabilidad por decisiones errÃ³neas
âš  CONSENTIMIENTO: Uso apropiado de datos de menores

6.3. REQUISITOS PARA IMPLEMENTACIÃ“N:
-------------------------------------
âœ“ Infraestructura tecnolÃ³gica adecuada
âœ“ Personal capacitado en interpretaciÃ³n de modelos
âœ“ Proceso de actualizaciÃ³n periÃ³dica de modelos
âœ“ Sistema de monitoreo de rendimiento en producciÃ³n
âœ“ Mecanismo de feedback para mejora continua
âœ“ Cumplimiento de normativas de protecciÃ³n de datos



7.1. MEJORAS EN DATOS:
-----------------------
ğŸ”¹ Incorporar variables temporales (tendencias de aprendizaje)
ğŸ”¹ Incluir datos de prÃ¡ctica y uso de inglÃ©s fuera del aula
ğŸ”¹ Recopilar informaciÃ³n sobre metodologÃ­as de enseÃ±anza
ğŸ”¹ Agregar datos de resultados en pruebas intermedias
ğŸ”¹ Considerar factores motivacionales y psicolÃ³gicos

7.2. MEJORAS EN MODELADO:
--------------------------
ğŸ”¹ Explorar deep learning (redes neuronales)
ğŸ”¹ Implementar modelos de explicabilidad (SHAP, LIME)
ğŸ”¹ Probar tÃ©cnicas de aprendizaje semi-supervisado
ğŸ”¹ Experimentar con meta-learning y AutoML
ğŸ”¹ Desarrollar modelos especÃ­ficos por regiÃ³n/contexto

7.3. MEJORAS EN EVALUACIÃ“N:
----------------------------
ğŸ”¹ Definir mÃ©tricas de negocio alineadas con objetivos educativos
ğŸ”¹ Realizar estudios longitudinales de impacto
ğŸ”¹ Implementar A/B testing de intervenciones
ğŸ”¹ Evaluar fairness y bias de manera sistemÃ¡tica
ğŸ”¹ Comparar con juicio de expertos educativos

7.4. DESPLIEGUE Y OPERACIÃ“N:
-----------------------------
ğŸ”¹ Desarrollar API REST para integraciÃ³n con sistemas educativos
ğŸ”¹ Crear dashboard interactivo para visualizaciÃ³n
ğŸ”¹ Implementar sistema de monitoreo de drift
ï¿½ï¿½ Establecer pipeline automatizado de reentrenamiento
ğŸ”¹ Documentar modelo y proceso para auditorÃ­a



â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                         CONCLUSIONES FINALES DEL PROYECTO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ LOGROS PRINCIPALES:

1. COMPRENSIÃ“N PROFUNDA DEL PROBLEMA:
   âœ“ AnÃ¡lisis exhaustivo del dataset de Pruebas Saber 11
   âœ“ IdentificaciÃ³n de patrones y relaciones significativas
   âœ“ CaracterizaciÃ³n del desafÃ­o de clasificaciÃ³n multiclase desbalanceada

2. IMPLEMENTACIÃ“N TÃ‰CNICA COMPLETA:
   âœ“ Pipeline completo desde EDA hasta deployment
   âœ“ MÃºltiples algoritmos de aprendizaje supervisado y no supervisado
   âœ“ TÃ©cnicas avanzadas: SMOTE, ensemble, feature engineering
   âœ“ EvaluaciÃ³n rigurosa con mÃ©tricas apropiadas

3. RESULTADOS SIGNIFICATIVOS:
   âœ“ Mejora sustancial sobre baseline mediante tÃ©cnicas avanzadas
   âœ“ IdentificaciÃ³n del mejor modelo para el problema
   âœ“ Insights accionables sobre factores que influyen en desempeÃ±o
   âœ“ ComparaciÃ³n exitosa de enfoques supervisados vs no supervisados

4. CONTRIBUCIÃ“N PRÃCTICA:
   âœ“ Herramienta potencial para apoyo a decisiones educativas
   âœ“ MetodologÃ­a replicable para problemas similares
   âœ“ DocumentaciÃ³n completa para futura implementaciÃ³n
   âœ“ IdentificaciÃ³n clara de limitaciones y mejoras

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’¡ LECCIONES CLAVE:

â€¢ El DESBALANCEO DE CLASES es un desafÃ­o central que requiere tÃ©cnicas especializadas
â€¢ ENSEMBLE METHODS superan consistentemente a modelos individuales
â€¢ BALANCED ACCURACY es mÃ¡s informativa que accuracy simple en problemas desbalanceados
â€¢ INTERPRETABILIDAD vs PERFORMANCE es un trade-off que debe manejarse segÃºn contexto
â€¢ La COMPARACIÃ“N SUPERVISADO vs NO SUPERVISADO revela complementariedad de enfoques

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš€ VALOR DEL PROYECTO:

ACADÃ‰MICO:
  â€¢ DemostraciÃ³n de dominio de tÃ©cnicas de ML supervisado y no supervisado
  â€¢ AplicaciÃ³n prÃ¡ctica de conceptos teÃ³ricos de Inteligencia Artificial
  â€¢ Desarrollo de habilidades de anÃ¡lisis crÃ­tico y toma de decisiones

PRÃCTICO:
  â€¢ SoluciÃ³n implementable para problema real en educaciÃ³n colombiana
  â€¢ Base para desarrollo de sistema de apoyo a estudiantes
  â€¢ MetodologÃ­a transferible a otros dominios educativos

SOCIAL:
  â€¢ ContribuciÃ³n potencial a reducciÃ³n de brechas educativas
  â€¢ Apoyo a mejora de calidad de educaciÃ³n en inglÃ©s
  â€¢ Herramienta para democratizaciÃ³n de oportunidades educativas

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ† REFLEXIÃ“N FINAL:

Este proyecto demuestra que el Machine Learning puede ser una herramienta poderosa
para abordar desafÃ­os educativos, pero su Ã©xito depende de:

1. ComprensiÃ³n profunda del dominio del problema
2. AplicaciÃ³n rigurosa de metodologÃ­as apropiadas
3. EvaluaciÃ³n crÃ­tica de resultados y limitaciones
4. ConsideraciÃ³n de implicaciones Ã©ticas y prÃ¡cticas
5. ComunicaciÃ³n efectiva de hallazgos a stakeholders

El camino del dato al insight, y del insight a la acciÃ³n, requiere no solo
competencia tÃ©cnica, sino tambiÃ©n pensamiento crÃ­tico, responsabilidad Ã©tica
y visiÃ³n del impacto real en las personas.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROYECTO COMPLETADO EXITOSAMENTE âœ“

Estudiantes: Flavio Arregoces, Cristian Gonzales
Universidad del Norte - IngenierÃ­a de Sistemas
Curso: Inteligencia Artificial (ELP 8012)
Profesor: Eduardo Zurek, Ph.D.
Noviembre 2025

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


================================================================================
FIN DEL REPORTE
================================================================================
