# ğŸ“˜ SECCIÃ“N 6: ImplementaciÃ³n en C con Docker

## ğŸ¯ DescripciÃ³n General

Esta secciÃ³n implementa un algoritmo de Machine Learning supervisado (K-Nearest Neighbors) en lenguaje C desde cero, demostrando comprensiÃ³n profunda del funcionamiento interno de los algoritmos de clasificaciÃ³n.

**ğŸ³ NOVEDAD**: La implementaciÃ³n estÃ¡ containerizada con Docker para mÃ¡xima portabilidad y facilidad de uso. Ver `SECCION6_DOCKER_QUICK_START.md` para inicio rÃ¡pido.

---

## ğŸ“‹ Contenido de la SecciÃ³n

### âœ… Tarea 21: SelecciÃ³n y JustificaciÃ³n del Algoritmo
**Objetivo**: Seleccionar un algoritmo de ML supervisado para implementar en C y justificar la elecciÃ³n.

**Algoritmo Seleccionado**: K-Nearest Neighbors (KNN)

**JustificaciÃ³n**:
- âœ… Simplicidad de implementaciÃ³n (no requiere entrenamiento complejo)
- âœ… Estructuras de datos simples (arrays)
- âœ… MatemÃ¡ticas bÃ¡sicas (distancia euclidiana)
- âœ… FÃ¡cil de entender y debuggear
- âœ… ComparaciÃ³n directa con sklearn

**Archivos Generados**:
- `tarea21_algorithm_selection.png`
- `tarea21_justificacion_algoritmo.txt`

---

### âœ… Tarea 22: DiseÃ±o de Estructuras y Funciones
**Objetivo**: DiseÃ±ar estructuras de datos y funciones con pseudocÃ³digo detallado.

**Estructuras Implementadas**:
1. `DataPoint`: Punto de datos con features y label
2. `Dataset`: Contenedor de mÃºltiples puntos
3. `Neighbor`: InformaciÃ³n de vecino cercano
4. `KNNModel`: Modelo KNN completo

**Funciones Principales**:
- `load_dataset()`: Carga datos desde CSV
- `euclidean_distance()`: Calcula distancia L2
- `knn_predict_single()`: Predice clase de un punto
- `knn_predict()`: Predice mÃºltiples puntos
- `majority_vote()`: VotaciÃ³n por mayorÃ­a
- `calculate_accuracy()`: Calcula accuracy
- `print_confusion_matrix()`: Matriz de confusiÃ³n
- `print_per_class_metrics()`: MÃ©tricas por clase

**Archivos Generados**:
- `tarea22_diseno_completo.txt`
- `tarea22_arquitectura_sistema.png`

---

### âœ… Tarea 23: ImplementaciÃ³n Completa en C (Containerizada con Docker)
**Objetivo**: Implementar completamente el algoritmo KNN en C.

**ğŸ³ ENFOQUE MODERNO**: En lugar de cÃ³digo C inline en el notebook, la implementaciÃ³n usa una estructura Docker profesional.

**CaracterÃ­sticas de la ImplementaciÃ³n**:
- âœ… 595 lÃ­neas de cÃ³digo C profesional
- âœ… CÃ³digo modular y bien documentado
- âœ… GestiÃ³n robusta de memoria (malloc/free)
- âœ… Manejo completo de errores
- âœ… Carga de datos desde CSV
- âœ… EvaluaciÃ³n con mÃºltiples mÃ©tricas
- âœ… Matrices de confusiÃ³n
- âœ… MÃ©tricas por clase (Precision, Recall, F1)
- âœ… **Containerizada con Docker para portabilidad**

**Estructura Docker**:
```
seccion6_c_docker/
â”œâ”€â”€ Dockerfile              # Imagen Docker (gcc:13.2.0)
â”œâ”€â”€ docker-compose.yml      # OrquestaciÃ³n simplificada
â”œâ”€â”€ README.md              # DocumentaciÃ³n completa
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ knn_classifier.c   # ImplementaciÃ³n completa (595 lÃ­neas)
â”‚   â””â”€â”€ Makefile           # Script de compilaciÃ³n
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train_data_c.csv   # Datos de entrenamiento (generados desde Python)
â”‚   â””â”€â”€ test_data_c.csv    # Datos de prueba (generados desde Python)
â”œâ”€â”€ results/
â”‚   â””â”€â”€ output.txt         # Resultados de ejecuciÃ³n
â””â”€â”€ scripts/
    â”œâ”€â”€ build.sh           # Script para construir imagen
    â””â”€â”€ run.sh             # Script para ejecutar contenedor
```

**CompilaciÃ³n y EjecuciÃ³n con Docker** (Recomendado):
```bash
cd seccion6_c_docker
docker-compose up --build
```

**EjecuciÃ³n tradicional** (Sin Docker):
```bash
cd seccion6_c_docker/src
make              # Compilar
make run          # Compilar y ejecutar
make test         # Probar con diferentes valores de k
make clean        # Limpiar archivos compilados
```

O manualmente:
```bash
cd seccion6_c_docker/src
gcc -o knn_classifier knn_classifier.c -lm -O2 -Wall -Wextra -std=c99
./knn_classifier ../data/train_data_c.csv ../data/test_data_c.csv 5
```

**Ventajas del Enfoque Docker**:
- ğŸ³ **Portabilidad**: Funciona igual en Windows, macOS y Linux
- ğŸ”„ **Reproducibilidad**: Siempre usa gcc:13.2.0
- ğŸ”’ **Aislamiento**: No interfiere con el sistema del usuario
- âš¡ **Facilidad**: No requiere instalar GCC manualmente
- ğŸ“ **Profesionalismo**: Enfoque moderno (DevOps)
- ğŸ“¦ **Limpieza**: No deja archivos compilados en el repositorio

---

### âœ… Tarea 24: EvaluaciÃ³n y ComparaciÃ³n Python vs C (Integrado con Docker)
**Objetivo**: Comparar la implementaciÃ³n en C con sklearn (Python).

**IntegraciÃ³n AutomÃ¡tica**: El notebook ejecuta Docker automÃ¡ticamente y lee los resultados.

**MÃ©tricas Comparadas**:
1. **Accuracy**: PrecisiÃ³n de clasificaciÃ³n
2. **Tiempo de EjecuciÃ³n**: Velocidad de predicciÃ³n
3. **Uso de Memoria**: EstimaciÃ³n cualitativa
4. **Facilidad de Uso**: AnÃ¡lisis subjetivo

**Workflow Integrado**:
```python
# El notebook ejecuta automÃ¡ticamente:
import subprocess
result = subprocess.run(['docker-compose', 'up', '--build'], ...)

# Lee resultados desde Docker:
with open('results/output.txt', 'r') as f:
    c_results = parse_results(f.read())

# Compara con Python:
compare_implementations(python_results, c_results)
```

**Resultados Esperados**:
- **Accuracy**: Similar (Â±1-2%)
- **Velocidad**: Python mÃ¡s rÃ¡pido (optimizaciones de sklearn)
- **Memoria**: C mÃ¡s eficiente
- **Facilidad**: Python mucho mÃ¡s fÃ¡cil de usar

**Archivos Generados**:
- `tarea24_comparison_python_vs_c.png`
- `tarea24_comparacion_completa.txt`
- `seccion6_c_docker/results/output.txt` (generado por Docker)

---

### âœ… Tarea 25: AnÃ¡lisis de Limitaciones y Optimizaciones
**Objetivo**: Analizar limitaciones de la implementaciÃ³n y proponer optimizaciones.

**Limitaciones Identificadas**:
1. Complejidad temporal O(n*d + n*log(n))
2. Complejidad espacial O(n*d)
3. Sin paralelizaciÃ³n
4. Sin estructuras de datos avanzadas (KD-Tree)
5. MAX_FEATURES fijo en compile-time
6. Parser CSV simple

**Optimizaciones Propuestas**:
1. **Heap Parcial**: O(n*log(k)) en lugar de O(n*log(n)) â†’ 2-5x speedup
2. **KD-Tree**: O(log(n)) bÃºsqueda â†’ 10-100x speedup
3. **OpenMP**: ParalelizaciÃ³n â†’ 4-16x speedup
4. **SIMD**: VectorizaciÃ³n â†’ 2-4x speedup
5. **LSH**: BÃºsqueda aproximada â†’ 50-1000x speedup
6. **CuantizaciÃ³n**: float en lugar de double â†’ 1.2-1.5x speedup
7. **SoA Layout**: Cache-friendly â†’ 1.2-1.3x speedup
8. **Early Stopping**: DetecciÃ³n temprana â†’ 1.1-1.3x speedup

**Speedup Total Estimado**: 100-500x con todas las optimizaciones

**Archivos Generados**:
- `tarea25_analisis_limitaciones.txt`
- `tarea25_optimizaciones_comparacion.png`

---

## ğŸš€ GuÃ­a de Uso RÃ¡pida

### Requisitos Previos
- Docker instalado ([Instrucciones de instalaciÃ³n](https://docs.docker.com/get-docker/))
- Docker Compose instalado (incluido con Docker Desktop)
- Python 3.8+ (para generar datos)

### Paso 1: Generar Datos desde Python
```bash
# Ejecutar notebook de Python (SecciÃ³n 6, Tarea 23)
cd notebooks
jupyter notebook seccion6.ipynb
# Ejecutar celdas hasta que se generen train_data_c.csv y test_data_c.csv
```

### Paso 2: Ejecutar con Docker
```bash
cd ../seccion6_c_docker

# OpciÃ³n A: Docker Compose (Recomendado)
docker-compose up --build

# OpciÃ³n B: Scripts auxiliares
./scripts/build.sh
./scripts/run.sh

# OpciÃ³n C: Docker manual
docker build -t knn_classifier_c .
docker run --rm \
  -v $(pwd)/data:/app/data:ro \
  -v $(pwd)/results:/app/results:rw \
  knn_classifier_c
```

### Paso 3: Ver Resultados
Los resultados se guardan automÃ¡ticamente en `results/output.txt` y se muestran en consola.

```bash
# Ver resultados
cat results/output.txt

# El notebook de Python los lee automÃ¡ticamente para comparaciÃ³n
```

### Alternativa: CompilaciÃ³n Local (Sin Docker)
```bash
cd seccion6_c_docker/src
make
./knn_classifier ../data/train_data_c.csv ../data/test_data_c.csv 5
```

---

## ğŸ“Š Output Esperado

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘    K-NEAREST NEIGHBORS (KNN) CLASSIFIER - IMPLEMENTACIÃ“N EN C     â•‘
â•‘                                                                    â•‘
â•‘    Universidad del Norte - Inteligencia Artificial (ELP 8012)     â•‘
â•‘    Proyecto: PredicciÃ³n de DesempeÃ±o en InglÃ©s - Saber 11         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ParÃ¡metros:
  Archivo de entrenamiento: train_data_c.csv
  Archivo de prueba: test_data_c.csv
  K (vecinos): 5

ğŸ“‚ Cargando datos de entrenamiento...
âœ… Datos de entrenamiento cargados:
  Muestras:        1000
  Features:        10
  Clases:          5

ğŸ“‚ Cargando datos de prueba...
âœ… Datos de prueba cargados:
  Muestras:        300
  Features:        10
  Clases:          5

ğŸ”§ Creando modelo KNN con k=5...
ğŸ¯ Entrenando modelo...
âœ… Modelo entrenado

Realizando predicciones...
[==================================================] 100%
âœ… Predicciones completadas en 1.23 segundos

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      RESULTADOS GENERALES              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Accuracy:              85.67%
  Total de muestras:     300
  Predicciones correctas: 257
  Predicciones incorrectas: 43

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      MATRIZ DE CONFUSIÃ“N               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
         C0   C1   C2   C3   C4  
      -------------------------
C0  |    45    3    2    0    0 
C1  |     2   52    4    2    0 
C2  |     1    5   48    5    1 
C3  |     0    1    4   51    4 
C4  |     0    0    2    3   55 

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      MÃ‰TRICAS POR CLASE                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Clase  PrecisiÃ³n  Recall    F1-Score
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  0     0.9375    0.9000    0.9184
  1     0.8525    0.8667    0.8596
  2     0.8000    0.8000    0.8000
  3     0.8361    0.8500    0.8430
  4     0.9167    0.9167    0.9167
```

---

## ğŸ“ Estructura de Archivos

```
Ia_EDA_analysis/
â”œâ”€â”€ knn_classifier.c                 # ImplementaciÃ³n completa en C (595 lÃ­neas)
â”œâ”€â”€ Makefile                         # Script de compilaciÃ³n
â”œâ”€â”€ train_data_c.csv                 # Datos de entrenamiento (generados)
â”œâ”€â”€ test_data_c.csv                  # Datos de prueba (generados)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ seccion6.ipynb              # Notebook completo con todas las tareas
â”œâ”€â”€ tarea21_algorithm_selection.png
â”œâ”€â”€ tarea21_justificacion_algoritmo.txt
â”œâ”€â”€ tarea22_diseno_completo.txt
â”œâ”€â”€ tarea22_arquitectura_sistema.png
â”œâ”€â”€ tarea24_comparison_python_vs_c.png
â”œâ”€â”€ tarea24_comparacion_completa.txt
â”œâ”€â”€ tarea25_analisis_limitaciones.txt
â”œâ”€â”€ tarea25_optimizaciones_comparacion.png
â””â”€â”€ resultados_knn_c.txt            # Resultados (generado al ejecutar)
```

---

## ğŸ”§ Troubleshooting

### Error: "No se pudo abrir el archivo train_data_c.csv"
**SoluciÃ³n**: Ejecutar el notebook de Python primero para generar los archivos CSV.

### Error: "undefined reference to sqrt"
**SoluciÃ³n**: Agregar `-lm` al comando de compilaciÃ³n para enlazar librerÃ­a matemÃ¡tica.

### Error: "gcc: command not found"
**SoluciÃ³n**: Instalar GCC:
- **Linux**: `sudo apt install build-essential`
- **Mac**: `xcode-select --install`
- **Windows**: Instalar MinGW o usar WSL

### Warning: "unused variable"
**SoluciÃ³n**: Los warnings son normales y no afectan la ejecuciÃ³n. Para compilar sin warnings, usar `-Wno-unused-variable`.

---

## ğŸ“š Referencias

### Algoritmo KNN
- Cover, T., & Hart, P. (1967). "Nearest neighbor pattern classification"
- Fix, E., & Hodges, J. L. (1951). "Discriminatory analysis"

### Implementaciones de Referencia
- scikit-learn KNN: https://github.com/scikit-learn/scikit-learn
- FAISS (Facebook AI): https://github.com/facebookresearch/faiss

### Optimizaciones
- Bentley, J. L. (1975). "Multidimensional binary search trees"
- Muja, M., & Lowe, D. G. (2009). "Fast approximate nearest neighbors with automatic algorithm configuration"

---

## ğŸ“ Aprendizajes Clave

1. **ComprensiÃ³n AlgorÃ­tmica**: Implementar desde cero demuestra dominio profundo del algoritmo
2. **Trade-offs**: Simplicidad vs OptimizaciÃ³n, Exactitud vs Velocidad
3. **GestiÃ³n de Memoria**: Control directo en C requiere disciplina
4. **ApreciaciÃ³n de LibrerÃ­as**: sklearn tiene dÃ©cadas de optimizaciones
5. **Valor Educativo**: Esta implementaciÃ³n es perfecta para aprendizaje

---

## ğŸ’¡ Conclusiones

### Para Uso en ProducciÃ³n:
- **Recomendado**: Python con sklearn (optimizado, confiable, mantenible)
- **Alternativa**: C con todas las optimizaciones (solo si necesario)

### Para Aprendizaje:
- **Ideal**: Esta implementaciÃ³n en C (demuestra comprensiÃ³n profunda)
- **Complemento**: Comparar con sklearn para entender optimizaciones

### LecciÃ³n Principal:
El valor de esta implementaciÃ³n NO es su velocidad o eficiencia, sino la **comprensiÃ³n profunda** que proporciona sobre el funcionamiento interno de los algoritmos de Machine Learning.

---

**Universidad del Norte** - IngenierÃ­a de Sistemas  
**Curso**: Inteligencia Artificial (ELP 8012)  
**Profesor**: Eduardo Zurek, Ph.D.  
**Estudiantes**: Flavio Arregoces, Cristian Gonzales  
**Fecha**: Noviembre 2025  

---

## ğŸ“ Notas Adicionales

- El cÃ³digo C estÃ¡ completamente documentado en espaÃ±ol
- Todas las funciones tienen comentarios explicativos
- El cÃ³digo sigue estÃ¡ndares de C99
- La implementaciÃ³n es educativa, no optimizada para producciÃ³n
- Para datasets grandes (>10,000 muestras), considerar optimizaciones propuestas en Tarea 25

---

**âœ… SecciÃ³n 6 Completada con Ã‰xito** ğŸ‰
