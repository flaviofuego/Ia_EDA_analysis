# ğŸ’» CÃ“DIGO FUENTE

Esta carpeta contiene todo el cÃ³digo fuente del proyecto (scripts Python e implementaciÃ³n en C).

---

## ğŸ“‚ Estructura

### ğŸ python/ - Scripts Python
Scripts auxiliares y herramientas de generaciÃ³n:

**Archivos:**
- `carga_analisis_base.ipynb` - Notebook de carga y anÃ¡lisis preliminar
- `carga_base.ipynb` - Notebook de carga del dataset base
- `seccion2_script.py` - Script de preprocesamiento (SecciÃ³n 2)
- `generate_section6_complete.py` - Generador completo de SecciÃ³n 6

**Uso:**
```bash
# Ejecutar script de preprocesamiento
python src/python/seccion2_script.py

# Generar secciÃ³n 6
python src/python/generate_section6_complete.py
```

---

### ğŸ”§ c_implementation/ - ImplementaciÃ³n KNN en C

**Arquitectura Docker:**
```
c_implementation/
â”œâ”€â”€ Dockerfile              # Imagen Docker (gcc:13.2.0)
â”œâ”€â”€ docker-compose.yml      # OrquestaciÃ³n de contenedores
â”œâ”€â”€ .dockerignore          # Archivos excluidos de Docker
â”œâ”€â”€ .gitignore             # Archivos excluidos de Git
â”œâ”€â”€ README.md              # DocumentaciÃ³n completa de la implementaciÃ³n
â”‚
â”œâ”€â”€ src/                   # CÃ³digo fuente C
â”‚   â”œâ”€â”€ knn_classifier.c   # ImplementaciÃ³n KNN (701 lÃ­neas)
â”‚   â””â”€â”€ Makefile          # Sistema de compilaciÃ³n
â”‚
â”œâ”€â”€ data/                  # Datos para C (generados desde Python)
â”‚   â”œâ”€â”€ train_data_c.csv  # 5,000 observaciones
â”‚   â””â”€â”€ test_data_c.csv   # 2,000 observaciones
â”‚
â”œâ”€â”€ results/               # Resultados de ejecuciÃ³n
â”‚   â””â”€â”€ [outputs del programa C]
â”‚
â””â”€â”€ scripts/               # Scripts de utilidad
    â”œâ”€â”€ build.sh          # Construir imagen Docker
    â””â”€â”€ run.sh            # Ejecutar contenedor
```

---

## ğŸ¯ ImplementaciÃ³n KNN en C (Tarea 23)

### CaracterÃ­sticas Principales

**Algoritmo:** K-Nearest Neighbors (KNN)
- **K Ã³ptimo**: 5 vecinos
- **MÃ©trica de distancia**: Euclidiana
- **MÃ©todo de votaciÃ³n**: MayorÃ­a simple
- **Clases**: 5 (A-, A1, A2, B1, B+)

**CÃ³digo:**
- **LÃ­neas totales**: 701 lÃ­neas de cÃ³digo puro C
- **Funciones**: 12 funciones principales
- **Estructuras de datos**: 4 estructuras (DataPoint, Dataset, Neighbor, KNNModel)

### Funciones Implementadas

**Carga de datos:**
1. `load_dataset()` - Carga CSV y parsea datos
2. `free_dataset()` - Libera memoria
3. `print_dataset_info()` - Muestra informaciÃ³n del dataset

**Algoritmo KNN:**
4. `euclidean_distance()` - Calcula distancia entre puntos
5. `compare_neighbors()` - Comparador para qsort
6. `find_k_nearest_neighbors()` - Encuentra k vecinos mÃ¡s cercanos
7. `majority_vote()` - VotaciÃ³n por mayorÃ­a
8. `predict()` - Predice clase de una muestra

**EvaluaciÃ³n:**
9. `evaluate_model()` - Calcula accuracy
10. `compute_confusion_matrix()` - Matriz de confusiÃ³n
11. `print_confusion_matrix()` - Imprime matriz
12. `compute_classification_metrics()` - Precision, Recall, F1-Score

---

## ğŸ³ EjecuciÃ³n con Docker (Recomendado)

### OpciÃ³n 1: Docker Compose (MÃ¡s fÃ¡cil)
```bash
cd src/c_implementation
docker-compose up --build
```

### OpciÃ³n 2: Docker CLI
```bash
cd src/c_implementation

# Construir imagen
docker build -t knn-classifier .

# Ejecutar contenedor
docker run -v $(pwd)/data:/app/data -v $(pwd)/results:/app/results knn-classifier
```

---

## ğŸ”¨ CompilaciÃ³n Manual (Sin Docker)

### Requisitos
- GCC 13.2.0 o superior
- Make
- Linux/Unix (recomendado) o WSL en Windows

### CompilaciÃ³n
```bash
cd src/c_implementation/src

# Compilar
make

# Ejecutar
./knn_classifier ../data/train_data_c.csv ../data/test_data_c.csv 5

# Limpiar binarios
make clean
```

---

## ğŸ“Š Complejidad del Algoritmo

**Complejidad temporal:**
- **Entrenamiento**: O(1) (solo almacena datos)
- **PredicciÃ³n (por muestra)**: O(n Ã— d)
  - n = tamaÃ±o del training set
  - d = nÃºmero de features
- **PredicciÃ³n total**: O(m Ã— n Ã— d)
  - m = tamaÃ±o del test set

**Complejidad espacial:**
- **Almacenamiento**: O(n Ã— d)
- **Vecinos temporales**: O(k)

---

## ğŸ¨ CaracterÃ­sticas de la ImplementaciÃ³n

### âœ… Implementado

- âœ… Lectura de archivos CSV
- âœ… Parseo de datos numÃ©ricos
- âœ… CÃ¡lculo de distancia Euclidiana
- âœ… BÃºsqueda de k vecinos (con qsort)
- âœ… VotaciÃ³n por mayorÃ­a
- âœ… EvaluaciÃ³n completa (Accuracy, Precision, Recall, F1-Score)
- âœ… Matriz de confusiÃ³n
- âœ… Barra de progreso
- âœ… GestiÃ³n de memoria (malloc/free)
- âœ… Manejo bÃ¡sico de errores

### ğŸ”§ Optimizaciones Propuestas (Tarea 25)

**Alto impacto (10-100x):**
- KD-Tree para bÃºsqueda de vecinos (O(log n))
- ParalelizaciÃ³n con OpenMP (speedup ~8x)

**Impacto medio (2-5x):**
- Partial Heap Sort (solo primeros k vecinos)
- SIMD para distancias (vectorizaciÃ³n)
- Memory Pool para allocaciones

**Bajo impacto (1.2-2x):**
- Distance Caching
- Branch prediction hints
- Compiler flags de optimizaciÃ³n (-O3)

---

## ğŸ“ˆ Resultados Esperados

**MÃ©tricas de desempeÃ±o:**
- Accuracy: ~45-50% (dataset desbalanceado)
- Tiempo de ejecuciÃ³n: ~2-5 segundos (5000 train, 2000 test)
- Memoria usada: ~2-3 MB

**ComparaciÃ³n Python vs C:**
- C es ~10-20x mÃ¡s rÃ¡pido que Python puro
- C usa ~5-10x menos memoria
- Python con sklearn es mÃ¡s rÃ¡pido (optimizado en C++)

---

## ğŸ“ Notas de Desarrollo

### Decisiones de DiseÃ±o

1. **Â¿Por quÃ© KNN?**
   - Simplicidad conceptual
   - No requiere entrenamiento complejo
   - Implementable en C sin bibliotecas externas
   - Valor educativo alto

2. **Â¿Por quÃ© k=5?**
   - Balance entre bias y variance
   - Funciona bien para 5 clases
   - Evita empates en votaciÃ³n

3. **Â¿Por quÃ© qsort?**
   - Biblioteca estÃ¡ndar de C
   - ImplementaciÃ³n eficiente
   - No requiere cÃ³digo adicional

### Limitaciones Conocidas

- **MAX_FEATURES**: Limitado a 100 features (constante)
- **Sin normalizaciÃ³n**: Los datos deben venir normalizados
- **Sin manejo de missing values**: Los datos deben estar completos
- **Sin paralelizaciÃ³n**: EjecuciÃ³n secuencial

---

## ğŸš€ PrÃ³ximos Pasos

Para mejorar la implementaciÃ³n:
1. Implementar KD-Tree
2. Agregar paralelizaciÃ³n con OpenMP
3. Optimizar con SIMD
4. Agregar validaciÃ³n cruzada
5. Implementar grid search para k Ã³ptimo

---

**Generado automÃ¡ticamente - Proyecto IA Universidad del Norte**
